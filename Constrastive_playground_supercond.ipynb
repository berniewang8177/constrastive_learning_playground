{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from trainer import fit,train_epoch\n",
    "import numpy as np\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GSenergy_pa_composition_average', 'BulkModulus_difference',\n",
       "       'NUnfilled_composition_average', 'Density_min_value',\n",
       "       'valence_composition_average', 'HHIr_composition_average',\n",
       "       'IsAlkalineEarth_composition_average', 'Density_arithmetic_average',\n",
       "       'BCCvolume_padiff_composition_average', 'HHIp_composition_average',\n",
       "       'ElectronAffinity_composition_average',\n",
       "       'NfUnfilled_composition_average', 'IsRareEarth_composition_average',\n",
       "       'IsHexagonal_composition_average',\n",
       "       'ThermalConductivity_composition_average',\n",
       "       'ElectricalConductivity_composition_average',\n",
       "       'IonicRadii_composition_average', 'Polarizability_min_value',\n",
       "       'NValance_composition_average', 'ElasticModulus_composition_average',\n",
       "       'AtomicRadii_composition_average', 'BCCmagmom_composition_average',\n",
       "       'BCCfermi_composition_average', 'NfUnfilled_max_value',\n",
       "       'BCCenergy_pa_composition_average', 'name', 'Tc', 'group', 'ln(Tc)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "drop_cols = [\n",
    "                 'name',\n",
    "                 'group',\n",
    "                 'Tc', 'ln(Tc)'\n",
    "                 ]\n",
    "data_set = pd.read_excel('./data/Supercon_data_features_selected.xlsx')\n",
    "data_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6252, 29)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_set = pd.read_csv('./data/friedman_data.csv')\n",
    "\n",
    "drop_columns = drop_cols\n",
    "# drop_columns = ['E_regression', 'E_regression_shift', 'group',\n",
    "#                'Material compositions 2', 'Material compositions 1']\n",
    "data_set = data_set.drop(drop_columns, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GSenergy_pa_composition_average</th>\n",
       "      <th>BulkModulus_difference</th>\n",
       "      <th>NUnfilled_composition_average</th>\n",
       "      <th>Density_min_value</th>\n",
       "      <th>valence_composition_average</th>\n",
       "      <th>HHIr_composition_average</th>\n",
       "      <th>IsAlkalineEarth_composition_average</th>\n",
       "      <th>Density_arithmetic_average</th>\n",
       "      <th>BCCvolume_padiff_composition_average</th>\n",
       "      <th>HHIp_composition_average</th>\n",
       "      <th>...</th>\n",
       "      <th>ElectricalConductivity_composition_average</th>\n",
       "      <th>IonicRadii_composition_average</th>\n",
       "      <th>Polarizability_min_value</th>\n",
       "      <th>NValance_composition_average</th>\n",
       "      <th>ElasticModulus_composition_average</th>\n",
       "      <th>AtomicRadii_composition_average</th>\n",
       "      <th>BCCmagmom_composition_average</th>\n",
       "      <th>BCCfermi_composition_average</th>\n",
       "      <th>NfUnfilled_max_value</th>\n",
       "      <th>BCCenergy_pa_composition_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.460136</td>\n",
       "      <td>166.9</td>\n",
       "      <td>2.920000</td>\n",
       "      <td>856.000</td>\n",
       "      <td>4.680000</td>\n",
       "      <td>3208.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>4491.750000</td>\n",
       "      <td>-1.386800</td>\n",
       "      <td>2724.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.192000</td>\n",
       "      <td>0.746800</td>\n",
       "      <td>4.310000</td>\n",
       "      <td>9.480000</td>\n",
       "      <td>101.328000</td>\n",
       "      <td>1.512000</td>\n",
       "      <td>0.844265</td>\n",
       "      <td>5.291937</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.285643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.160523</td>\n",
       "      <td>130.4</td>\n",
       "      <td>2.190217</td>\n",
       "      <td>1.429</td>\n",
       "      <td>2.097050</td>\n",
       "      <td>1190.993789</td>\n",
       "      <td>0.128106</td>\n",
       "      <td>4025.485800</td>\n",
       "      <td>-0.933531</td>\n",
       "      <td>1977.872671</td>\n",
       "      <td>...</td>\n",
       "      <td>15.566382</td>\n",
       "      <td>1.210171</td>\n",
       "      <td>0.802000</td>\n",
       "      <td>6.361025</td>\n",
       "      <td>35.648292</td>\n",
       "      <td>1.152069</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>3.685240</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.893468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.546561</td>\n",
       "      <td>152.0</td>\n",
       "      <td>3.501429</td>\n",
       "      <td>1.429</td>\n",
       "      <td>2.252857</td>\n",
       "      <td>1391.857143</td>\n",
       "      <td>0.041429</td>\n",
       "      <td>5319.485800</td>\n",
       "      <td>-0.926104</td>\n",
       "      <td>3021.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>8.975857</td>\n",
       "      <td>1.239171</td>\n",
       "      <td>0.802000</td>\n",
       "      <td>5.798571</td>\n",
       "      <td>31.270000</td>\n",
       "      <td>1.147096</td>\n",
       "      <td>0.014631</td>\n",
       "      <td>4.367115</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.195665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-8.496939</td>\n",
       "      <td>127.0</td>\n",
       "      <td>6.287500</td>\n",
       "      <td>7310.000</td>\n",
       "      <td>4.712500</td>\n",
       "      <td>7183.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9243.333333</td>\n",
       "      <td>-1.736438</td>\n",
       "      <td>7171.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.008750</td>\n",
       "      <td>0.690500</td>\n",
       "      <td>7.060000</td>\n",
       "      <td>7.737500</td>\n",
       "      <td>89.075000</td>\n",
       "      <td>1.480125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.884944</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.482146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.237486</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2.589520</td>\n",
       "      <td>1.429</td>\n",
       "      <td>2.229258</td>\n",
       "      <td>1292.576419</td>\n",
       "      <td>0.098253</td>\n",
       "      <td>5807.485800</td>\n",
       "      <td>-1.069569</td>\n",
       "      <td>2244.541485</td>\n",
       "      <td>...</td>\n",
       "      <td>10.921397</td>\n",
       "      <td>1.236245</td>\n",
       "      <td>0.802000</td>\n",
       "      <td>7.266376</td>\n",
       "      <td>28.875546</td>\n",
       "      <td>1.152675</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>4.003412</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.918519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6247</th>\n",
       "      <td>-4.020242</td>\n",
       "      <td>130.4</td>\n",
       "      <td>1.598456</td>\n",
       "      <td>1.429</td>\n",
       "      <td>2.077220</td>\n",
       "      <td>1216.602317</td>\n",
       "      <td>0.154440</td>\n",
       "      <td>5624.485800</td>\n",
       "      <td>-0.949672</td>\n",
       "      <td>1835.907336</td>\n",
       "      <td>...</td>\n",
       "      <td>13.902703</td>\n",
       "      <td>1.219459</td>\n",
       "      <td>-5.816667</td>\n",
       "      <td>7.019305</td>\n",
       "      <td>35.150579</td>\n",
       "      <td>1.168440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.163053</td>\n",
       "      <td>4</td>\n",
       "      <td>-2.766734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6248</th>\n",
       "      <td>-4.054813</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1.869537</td>\n",
       "      <td>1.429</td>\n",
       "      <td>2.424005</td>\n",
       "      <td>1595.890411</td>\n",
       "      <td>0.163079</td>\n",
       "      <td>5520.885800</td>\n",
       "      <td>-1.503637</td>\n",
       "      <td>2117.742988</td>\n",
       "      <td>...</td>\n",
       "      <td>13.176778</td>\n",
       "      <td>1.188650</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>9.065884</td>\n",
       "      <td>25.505545</td>\n",
       "      <td>1.165225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.923896</td>\n",
       "      <td>8</td>\n",
       "      <td>-2.783499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249</th>\n",
       "      <td>-4.548996</td>\n",
       "      <td>112.0</td>\n",
       "      <td>3.573929</td>\n",
       "      <td>1.429</td>\n",
       "      <td>2.254286</td>\n",
       "      <td>1382.714286</td>\n",
       "      <td>0.031429</td>\n",
       "      <td>4967.485800</td>\n",
       "      <td>-0.908696</td>\n",
       "      <td>3062.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.296071</td>\n",
       "      <td>1.238861</td>\n",
       "      <td>-5.816667</td>\n",
       "      <td>5.826071</td>\n",
       "      <td>30.889643</td>\n",
       "      <td>1.144599</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>4.412494</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.197352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6250</th>\n",
       "      <td>-3.936502</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1.785750</td>\n",
       "      <td>1.429</td>\n",
       "      <td>2.282375</td>\n",
       "      <td>1274.437500</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>5133.775571</td>\n",
       "      <td>-1.085245</td>\n",
       "      <td>1831.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.592875</td>\n",
       "      <td>1.206036</td>\n",
       "      <td>0.802000</td>\n",
       "      <td>9.272250</td>\n",
       "      <td>30.471062</td>\n",
       "      <td>1.209046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.801802</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.769327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6251</th>\n",
       "      <td>-3.940685</td>\n",
       "      <td>130.4</td>\n",
       "      <td>1.728682</td>\n",
       "      <td>1.429</td>\n",
       "      <td>2.077519</td>\n",
       "      <td>1213.178295</td>\n",
       "      <td>0.155039</td>\n",
       "      <td>5128.285800</td>\n",
       "      <td>-0.951938</td>\n",
       "      <td>1841.085271</td>\n",
       "      <td>...</td>\n",
       "      <td>14.751938</td>\n",
       "      <td>1.220930</td>\n",
       "      <td>0.802000</td>\n",
       "      <td>6.891473</td>\n",
       "      <td>33.488372</td>\n",
       "      <td>1.177907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.121443</td>\n",
       "      <td>11</td>\n",
       "      <td>-2.698141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6252 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      GSenergy_pa_composition_average  BulkModulus_difference  \\\n",
       "0                           -5.460136                   166.9   \n",
       "1                           -4.160523                   130.4   \n",
       "2                           -4.546561                   152.0   \n",
       "3                           -8.496939                   127.0   \n",
       "4                           -4.237486                   112.0   \n",
       "...                               ...                     ...   \n",
       "6247                        -4.020242                   130.4   \n",
       "6248                        -4.054813                   123.0   \n",
       "6249                        -4.548996                   112.0   \n",
       "6250                        -3.936502                   123.0   \n",
       "6251                        -3.940685                   130.4   \n",
       "\n",
       "      NUnfilled_composition_average  Density_min_value  \\\n",
       "0                          2.920000            856.000   \n",
       "1                          2.190217              1.429   \n",
       "2                          3.501429              1.429   \n",
       "3                          6.287500           7310.000   \n",
       "4                          2.589520              1.429   \n",
       "...                             ...                ...   \n",
       "6247                       1.598456              1.429   \n",
       "6248                       1.869537              1.429   \n",
       "6249                       3.573929              1.429   \n",
       "6250                       1.785750              1.429   \n",
       "6251                       1.728682              1.429   \n",
       "\n",
       "      valence_composition_average  HHIr_composition_average  \\\n",
       "0                        4.680000               3208.000000   \n",
       "1                        2.097050               1190.993789   \n",
       "2                        2.252857               1391.857143   \n",
       "3                        4.712500               7183.750000   \n",
       "4                        2.229258               1292.576419   \n",
       "...                           ...                       ...   \n",
       "6247                     2.077220               1216.602317   \n",
       "6248                     2.424005               1595.890411   \n",
       "6249                     2.254286               1382.714286   \n",
       "6250                     2.282375               1274.437500   \n",
       "6251                     2.077519               1213.178295   \n",
       "\n",
       "      IsAlkalineEarth_composition_average  Density_arithmetic_average  \\\n",
       "0                                0.080000                 4491.750000   \n",
       "1                                0.128106                 4025.485800   \n",
       "2                                0.041429                 5319.485800   \n",
       "3                                0.000000                 9243.333333   \n",
       "4                                0.098253                 5807.485800   \n",
       "...                                   ...                         ...   \n",
       "6247                             0.154440                 5624.485800   \n",
       "6248                             0.163079                 5520.885800   \n",
       "6249                             0.031429                 4967.485800   \n",
       "6250                             0.156250                 5133.775571   \n",
       "6251                             0.155039                 5128.285800   \n",
       "\n",
       "      BCCvolume_padiff_composition_average  HHIp_composition_average  ...  \\\n",
       "0                                -1.386800               2724.000000  ...   \n",
       "1                                -0.933531               1977.872671  ...   \n",
       "2                                -0.926104               3021.857143  ...   \n",
       "3                                -1.736438               7171.250000  ...   \n",
       "4                                -1.069569               2244.541485  ...   \n",
       "...                                    ...                       ...  ...   \n",
       "6247                             -0.949672               1835.907336  ...   \n",
       "6248                             -1.503637               2117.742988  ...   \n",
       "6249                             -0.908696               3062.000000  ...   \n",
       "6250                             -1.085245               1831.250000  ...   \n",
       "6251                             -0.951938               1841.085271  ...   \n",
       "\n",
       "      ElectricalConductivity_composition_average  \\\n",
       "0                                       8.192000   \n",
       "1                                      15.566382   \n",
       "2                                       8.975857   \n",
       "3                                       7.008750   \n",
       "4                                      10.921397   \n",
       "...                                          ...   \n",
       "6247                                   13.902703   \n",
       "6248                                   13.176778   \n",
       "6249                                    9.296071   \n",
       "6250                                   13.592875   \n",
       "6251                                   14.751938   \n",
       "\n",
       "      IonicRadii_composition_average  Polarizability_min_value  \\\n",
       "0                           0.746800                  4.310000   \n",
       "1                           1.210171                  0.802000   \n",
       "2                           1.239171                  0.802000   \n",
       "3                           0.690500                  7.060000   \n",
       "4                           1.236245                  0.802000   \n",
       "...                              ...                       ...   \n",
       "6247                        1.219459                 -5.816667   \n",
       "6248                        1.188650                  0.400000   \n",
       "6249                        1.238861                 -5.816667   \n",
       "6250                        1.206036                  0.802000   \n",
       "6251                        1.220930                  0.802000   \n",
       "\n",
       "      NValance_composition_average  ElasticModulus_composition_average  \\\n",
       "0                         9.480000                          101.328000   \n",
       "1                         6.361025                           35.648292   \n",
       "2                         5.798571                           31.270000   \n",
       "3                         7.737500                           89.075000   \n",
       "4                         7.266376                           28.875546   \n",
       "...                            ...                                 ...   \n",
       "6247                      7.019305                           35.150579   \n",
       "6248                      9.065884                           25.505545   \n",
       "6249                      5.826071                           30.889643   \n",
       "6250                      9.272250                           30.471062   \n",
       "6251                      6.891473                           33.488372   \n",
       "\n",
       "      AtomicRadii_composition_average  BCCmagmom_composition_average  \\\n",
       "0                            1.512000                       0.844265   \n",
       "1                            1.152069                       0.000078   \n",
       "2                            1.147096                       0.014631   \n",
       "3                            1.480125                       0.000000   \n",
       "4                            1.152675                       0.000097   \n",
       "...                               ...                            ...   \n",
       "6247                         1.168440                       0.000000   \n",
       "6248                         1.165225                       0.000000   \n",
       "6249                         1.144599                       0.000205   \n",
       "6250                         1.209046                       0.000000   \n",
       "6251                         1.177907                       0.000000   \n",
       "\n",
       "      BCCfermi_composition_average  NfUnfilled_max_value  \\\n",
       "0                         5.291937                     0   \n",
       "1                         3.685240                     0   \n",
       "2                         4.367115                     0   \n",
       "3                         5.884944                     0   \n",
       "4                         4.003412                     0   \n",
       "...                            ...                   ...   \n",
       "6247                      3.163053                     4   \n",
       "6248                      3.923896                     8   \n",
       "6249                      4.412494                     0   \n",
       "6250                      3.801802                     3   \n",
       "6251                      3.121443                    11   \n",
       "\n",
       "      BCCenergy_pa_composition_average  \n",
       "0                            -5.285643  \n",
       "1                            -2.893468  \n",
       "2                            -3.195665  \n",
       "3                            -8.482146  \n",
       "4                            -2.918519  \n",
       "...                                ...  \n",
       "6247                         -2.766734  \n",
       "6248                         -2.783499  \n",
       "6249                         -3.197352  \n",
       "6250                         -2.769327  \n",
       "6251                         -2.698141  \n",
       "\n",
       "[6252 rows x 25 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data loaders\n",
    "from datasets import TripletSampling, BatchPairSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GSenergy_pa_composition_average</th>\n",
       "      <th>BulkModulus_difference</th>\n",
       "      <th>NUnfilled_composition_average</th>\n",
       "      <th>Density_min_value</th>\n",
       "      <th>valence_composition_average</th>\n",
       "      <th>HHIr_composition_average</th>\n",
       "      <th>IsAlkalineEarth_composition_average</th>\n",
       "      <th>Density_arithmetic_average</th>\n",
       "      <th>BCCvolume_padiff_composition_average</th>\n",
       "      <th>HHIp_composition_average</th>\n",
       "      <th>...</th>\n",
       "      <th>ElectricalConductivity_composition_average</th>\n",
       "      <th>IonicRadii_composition_average</th>\n",
       "      <th>Polarizability_min_value</th>\n",
       "      <th>NValance_composition_average</th>\n",
       "      <th>ElasticModulus_composition_average</th>\n",
       "      <th>AtomicRadii_composition_average</th>\n",
       "      <th>BCCmagmom_composition_average</th>\n",
       "      <th>BCCfermi_composition_average</th>\n",
       "      <th>NfUnfilled_max_value</th>\n",
       "      <th>BCCenergy_pa_composition_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-7.027184</td>\n",
       "      <td>112.0</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>7310.000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>5200.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7940.000000</td>\n",
       "      <td>-4.027500</td>\n",
       "      <td>5550.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.650000</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>7.060</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.524500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.976185</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.994123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.990110</td>\n",
       "      <td>138.1</td>\n",
       "      <td>1.931298</td>\n",
       "      <td>1.429</td>\n",
       "      <td>2.419847</td>\n",
       "      <td>1603.816794</td>\n",
       "      <td>0.152672</td>\n",
       "      <td>4004.685800</td>\n",
       "      <td>-1.094504</td>\n",
       "      <td>2035.877863</td>\n",
       "      <td>...</td>\n",
       "      <td>14.465649</td>\n",
       "      <td>1.259084</td>\n",
       "      <td>0.802</td>\n",
       "      <td>7.061069</td>\n",
       "      <td>35.297710</td>\n",
       "      <td>1.193588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.086259</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.844674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.172174</td>\n",
       "      <td>130.4</td>\n",
       "      <td>2.060883</td>\n",
       "      <td>1.429</td>\n",
       "      <td>2.091324</td>\n",
       "      <td>1248.097412</td>\n",
       "      <td>0.152207</td>\n",
       "      <td>4239.571500</td>\n",
       "      <td>-1.114460</td>\n",
       "      <td>2035.768645</td>\n",
       "      <td>...</td>\n",
       "      <td>13.776256</td>\n",
       "      <td>1.201218</td>\n",
       "      <td>0.802</td>\n",
       "      <td>6.334855</td>\n",
       "      <td>33.698630</td>\n",
       "      <td>1.158113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.165391</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.905431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-8.586122</td>\n",
       "      <td>148.0</td>\n",
       "      <td>6.212500</td>\n",
       "      <td>5727.000</td>\n",
       "      <td>4.787500</td>\n",
       "      <td>7090.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7202.333333</td>\n",
       "      <td>-1.830375</td>\n",
       "      <td>7051.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.941250</td>\n",
       "      <td>0.652625</td>\n",
       "      <td>4.310</td>\n",
       "      <td>7.287500</td>\n",
       "      <td>90.087500</td>\n",
       "      <td>1.468125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.842407</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.555724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.917395</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1.602649</td>\n",
       "      <td>1.429</td>\n",
       "      <td>2.397351</td>\n",
       "      <td>1758.278146</td>\n",
       "      <td>0.198675</td>\n",
       "      <td>4576.285800</td>\n",
       "      <td>-1.591225</td>\n",
       "      <td>1996.688742</td>\n",
       "      <td>...</td>\n",
       "      <td>10.894040</td>\n",
       "      <td>1.217219</td>\n",
       "      <td>0.400</td>\n",
       "      <td>8.913907</td>\n",
       "      <td>24.304636</td>\n",
       "      <td>1.201258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.767946</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.667793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GSenergy_pa_composition_average  BulkModulus_difference  \\\n",
       "0                        -7.027184                   112.0   \n",
       "1                        -3.990110                   138.1   \n",
       "2                        -4.172174                   130.4   \n",
       "3                        -8.586122                   148.0   \n",
       "4                        -3.917395                   123.0   \n",
       "\n",
       "   NUnfilled_composition_average  Density_min_value  \\\n",
       "0                       5.500000           7310.000   \n",
       "1                       1.931298              1.429   \n",
       "2                       2.060883              1.429   \n",
       "3                       6.212500           5727.000   \n",
       "4                       1.602649              1.429   \n",
       "\n",
       "   valence_composition_average  HHIr_composition_average  \\\n",
       "0                     4.500000               5200.000000   \n",
       "1                     2.419847               1603.816794   \n",
       "2                     2.091324               1248.097412   \n",
       "3                     4.787500               7090.000000   \n",
       "4                     2.397351               1758.278146   \n",
       "\n",
       "   IsAlkalineEarth_composition_average  Density_arithmetic_average  \\\n",
       "0                             0.000000                 7940.000000   \n",
       "1                             0.152672                 4004.685800   \n",
       "2                             0.152207                 4239.571500   \n",
       "3                             0.000000                 7202.333333   \n",
       "4                             0.198675                 4576.285800   \n",
       "\n",
       "   BCCvolume_padiff_composition_average  HHIp_composition_average  ...  \\\n",
       "0                             -4.027500               5550.000000  ...   \n",
       "1                             -1.094504               2035.877863  ...   \n",
       "2                             -1.114460               2035.768645  ...   \n",
       "3                             -1.830375               7051.250000  ...   \n",
       "4                             -1.591225               1996.688742  ...   \n",
       "\n",
       "   ElectricalConductivity_composition_average  IonicRadii_composition_average  \\\n",
       "0                                    7.650000                        0.675000   \n",
       "1                                   14.465649                        1.259084   \n",
       "2                                   13.776256                        1.201218   \n",
       "3                                    6.941250                        0.652625   \n",
       "4                                   10.894040                        1.217219   \n",
       "\n",
       "   Polarizability_min_value  NValance_composition_average  \\\n",
       "0                     7.060                      9.500000   \n",
       "1                     0.802                      7.061069   \n",
       "2                     0.802                      6.334855   \n",
       "3                     4.310                      7.287500   \n",
       "4                     0.400                      8.913907   \n",
       "\n",
       "   ElasticModulus_composition_average  AtomicRadii_composition_average  \\\n",
       "0                           77.000000                         1.524500   \n",
       "1                           35.297710                         1.193588   \n",
       "2                           33.698630                         1.158113   \n",
       "3                           90.087500                         1.468125   \n",
       "4                           24.304636                         1.201258   \n",
       "\n",
       "   BCCmagmom_composition_average  BCCfermi_composition_average  \\\n",
       "0                            0.0                      6.976185   \n",
       "1                            0.0                      3.086259   \n",
       "2                            0.0                      3.165391   \n",
       "3                            0.0                      5.842407   \n",
       "4                            0.0                      3.767946   \n",
       "\n",
       "   NfUnfilled_max_value  BCCenergy_pa_composition_average  \n",
       "0                     0                         -6.994123  \n",
       "1                     0                         -2.844674  \n",
       "2                     0                         -2.905431  \n",
       "3                     0                         -8.555724  \n",
       "4                     0                         -2.667793  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_shuffled = data_set.sample(frac=1).reset_index(drop=True)\n",
    "data_set_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake labels for pos/neg\n",
    "labels = [1]* int(0.5 * data_set_shuffled.shape[0]) + [0]*int( 0.5 * data_set_shuffled.shape[0] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -7.02718431, 112.        ,   5.5       , ...,   6.97618467,\n",
       "          0.        ,  -6.99412349],\n",
       "       [ -3.99011003, 138.1       ,   1.93129771, ...,   3.08625886,\n",
       "          0.        ,  -2.84467423],\n",
       "       [ -4.17217352, 130.4       ,   2.0608828 , ...,   3.16539085,\n",
       "          0.        ,  -2.90543056],\n",
       "       ...,\n",
       "       [ -5.61941375, 148.        ,   3.57068063, ...,   4.92502584,\n",
       "          5.        ,  -4.9744114 ],\n",
       "       [ -4.13723714, 130.4       ,   2.07713074, ...,   3.17429372,\n",
       "         11.        ,  -2.88486656],\n",
       "       [ -4.1473767 , 275.        ,   2.525     , ...,   7.19047362,\n",
       "          0.        ,  -3.27683474]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set_shuffled.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_shuffled = torch.tensor(data_set_shuffled.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloader = TripletSampling( dataset = data_set_shuffled , labels=labels)\n",
    "datasampler = BatchPairSampling( dataset = data_set_shuffled , labels=labels)\n",
    "batch_size = 10\n",
    "train_loader = torch.utils.data.DataLoader(datasampler, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([10, 25])\n"
     ]
    }
   ],
   "source": [
    "for batch,_ in train_loader:\n",
    "    print(len(batch))\n",
    "    print(batch[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks import EmbeddingNet, TripletNet, SiameseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = data_set_shuffled.shape[1]\n",
    "hidden_size = 100\n",
    "embedding_size = 10\n",
    "net = EmbeddingNet(input_size, hidden_size, embedding_size)\n",
    "# triplet_net = TripletNet(  embedding_net = net )\n",
    "siamese_net = SiameseNet(  embedding_net = net )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.rand( 1,25)\n",
    "x2 = torch.rand( 1,25)\n",
    "# x3 = torch.rand( 1,24)\n",
    "emb1, emb2 = siamese_net(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 10\n"
     ]
    }
   ],
   "source": [
    "result = siamese_net(*batch)\n",
    "print(len(result), len(result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2623)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(3,5)\n",
    "b = torch.rand(3,5)\n",
    "sim_a = torch.cdist(a,a, p = 2).flatten()\n",
    "non_zero = torch.nonzero( sim_a )\n",
    "torch.max( sim_a[non_zero] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from losses import TripletLoss, HardNegativesBatchLoss\n",
    "\n",
    "def euclidean(a,b):\n",
    "    if len(a.shape) == 1:\n",
    "        a = torch.unsqueeze(a,0)\n",
    "        b = torch.unsqueeze(b,0)\n",
    "#     print(a)\n",
    "#     print(b)\n",
    "    return (a - b).pow(2).sum(1)\n",
    "\n",
    "margin = 1\n",
    "distance = euclidean\n",
    "# loss_fn = TripletLoss( margin = margin, distance = distance)\n",
    "loss_fn = HardNegativesBatchLoss( margin = margin, distance = distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5916, grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(*result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = HardNegativesBatchLoss( margin = margin, distance = distance)\n",
    "lr = 1e-3\n",
    "\n",
    "hidden_size = 100\n",
    "embedding_size = 20\n",
    "net = EmbeddingNet(input_size, hidden_size, embedding_size)\n",
    "# triplet_net = TripletNet(  embedding_net = net )\n",
    "siamese_net = SiameseNet(  embedding_net = net )\n",
    "\n",
    "\n",
    "model = siamese_net\n",
    "model = model.float() \n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
    "n_epochs = 200\n",
    "\n",
    "datasampler = BatchPairSampling( dataset = data_set_shuffled , labels=labels)\n",
    "batch_size = 20\n",
    "train_loader = torch.utils.data.DataLoader(datasampler, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "interval = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [0/6252 (0%)]\tLoss: 1.349043\n",
      "Train: [400/6252 (6%)]\tLoss: 1.039437\n",
      "Train: [800/6252 (13%)]\tLoss: 0.853305\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.496333\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.429587\n",
      "Train: [2000/6252 (32%)]\tLoss: 1.023495\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.710150\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.662580\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.230442\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.974719\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.386161\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.649327\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.569785\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.407379\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.642104\n",
      "Train: [6000/6252 (96%)]\tLoss: 1.259609\n",
      "Epoch: 1/200. Train set: Average loss: 0.6837\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.483704\n",
      "Train: [800/6252 (13%)]\tLoss: 1.011144\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.651239\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.368848\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.577126\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.820799\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.393427\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.531337\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.614565\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.389637\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.631388\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.260745\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.600689\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.401769\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.242712\n",
      "Epoch: 2/200. Train set: Average loss: 0.5352\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.547638\n",
      "Train: [800/6252 (13%)]\tLoss: 0.412535\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.507842\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.503643\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.390071\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.377441\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.575435\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.710564\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.536526\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.501329\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.386891\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.350087\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.615296\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.733695\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.613899\n",
      "Epoch: 3/200. Train set: Average loss: 0.5239\n",
      "Train: [0/6252 (0%)]\tLoss: 1.232216\n",
      "Train: [400/6252 (6%)]\tLoss: 0.638129\n",
      "Train: [800/6252 (13%)]\tLoss: 0.478531\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.507903\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.586454\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.578096\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.557114\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.420134\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.321870\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.684937\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.579304\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.484650\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.828592\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.382985\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.352652\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.972335\n",
      "Epoch: 4/200. Train set: Average loss: 0.5596\n",
      "Train: [0/6252 (0%)]\tLoss: 0.965309\n",
      "Train: [400/6252 (6%)]\tLoss: 0.759060\n",
      "Train: [800/6252 (13%)]\tLoss: 0.811276\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.521206\n",
      "Train: [1600/6252 (26%)]\tLoss: 1.020322\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.538907\n",
      "Train: [2400/6252 (38%)]\tLoss: 1.030929\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.642938\n",
      "Train: [3200/6252 (51%)]\tLoss: 1.017026\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.758120\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.387719\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.486984\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.536905\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.753991\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.676491\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.398821\n",
      "Epoch: 5/200. Train set: Average loss: 0.6835\n",
      "Train: [0/6252 (0%)]\tLoss: 0.888805\n",
      "Train: [400/6252 (6%)]\tLoss: 0.731169\n",
      "Train: [800/6252 (13%)]\tLoss: 0.530937\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.579756\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.336034\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.397427\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.571624\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.373011\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.710620\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.540218\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.611157\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.507459\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.351254\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.403695\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.551870\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.549404\n",
      "Epoch: 6/200. Train set: Average loss: 0.5139\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.494931\n",
      "Train: [800/6252 (13%)]\tLoss: 0.540926\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.697980\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.500256\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.398835\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.578609\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.509831\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.651954\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.552671\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.611577\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.398034\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.474325\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.706385\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.653913\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.622343\n",
      "Epoch: 7/200. Train set: Average loss: 0.5669\n",
      "Train: [0/6252 (0%)]\tLoss: 1.000259\n",
      "Train: [400/6252 (6%)]\tLoss: 0.490870\n",
      "Train: [800/6252 (13%)]\tLoss: 0.469546\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.416726\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.757983\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.377529\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.399640\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.449912\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.401207\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.271112\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.593968\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.686358\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.359019\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.687291\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.656775\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.618924\n",
      "Epoch: 8/200. Train set: Average loss: 0.5187\n",
      "Train: [0/6252 (0%)]\tLoss: 1.139664\n",
      "Train: [400/6252 (6%)]\tLoss: 0.446161\n",
      "Train: [800/6252 (13%)]\tLoss: 0.469227\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.395894\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.229513\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.245792\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.694411\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.604420\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.287297\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.219281\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.677680\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.475117\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.252845\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.359038\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.493893\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.466774\n",
      "Epoch: 9/200. Train set: Average loss: 0.4241\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.277921\n",
      "Train: [800/6252 (13%)]\tLoss: 0.446807\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.733909\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.475240\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.502858\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.324409\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.526321\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.858735\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.527737\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.475573\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.682066\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.778502\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.690742\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.433834\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.448639\n",
      "Epoch: 10/200. Train set: Average loss: 0.5443\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.570652\n",
      "Train: [800/6252 (13%)]\tLoss: 0.560459\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.443408\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.706637\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.338433\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.600865\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.559118\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.635221\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.543097\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.458403\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.534162\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.577903\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.605334\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.298166\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.429463\n",
      "Epoch: 11/200. Train set: Average loss: 0.5311\n",
      "Train: [0/6252 (0%)]\tLoss: 0.994934\n",
      "Train: [400/6252 (6%)]\tLoss: 0.548093\n",
      "Train: [800/6252 (13%)]\tLoss: 0.605067\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.601664\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.596677\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.450805\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.698897\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.605363\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.440609\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.495404\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.595801\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.242388\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.509961\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.550921\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.605509\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.482586\n",
      "Epoch: 12/200. Train set: Average loss: 0.5452\n",
      "Train: [0/6252 (0%)]\tLoss: 1.091385\n",
      "Train: [400/6252 (6%)]\tLoss: 0.540944\n",
      "Train: [800/6252 (13%)]\tLoss: 0.462797\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.549926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [1600/6252 (26%)]\tLoss: 0.444641\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.438816\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.658992\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.509085\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.549012\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.347731\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.447735\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.500488\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.412571\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.540401\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.620485\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.604856\n",
      "Epoch: 13/200. Train set: Average loss: 0.5041\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.475382\n",
      "Train: [800/6252 (13%)]\tLoss: 0.698391\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.414429\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.389115\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.249396\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.435755\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.500080\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.516523\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.504243\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.737534\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.644375\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.346520\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.506199\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.287367\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.454652\n",
      "Epoch: 14/200. Train set: Average loss: 0.4764\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.580266\n",
      "Train: [800/6252 (13%)]\tLoss: 0.393703\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.471088\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.505248\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.567082\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.484320\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.325006\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.530634\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.364146\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.588783\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.317041\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.574931\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.350046\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.623333\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.536271\n",
      "Epoch: 15/200. Train set: Average loss: 0.4750\n",
      "Train: [0/6252 (0%)]\tLoss: 1.275513\n",
      "Train: [400/6252 (6%)]\tLoss: 0.670544\n",
      "Train: [800/6252 (13%)]\tLoss: 0.672748\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.495935\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.383160\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.531305\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.556343\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.346370\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.501300\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.601367\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.546390\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.392448\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.589326\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.427662\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.533616\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.468004\n",
      "Epoch: 16/200. Train set: Average loss: 0.5202\n",
      "Train: [0/6252 (0%)]\tLoss: 0.781708\n",
      "Train: [400/6252 (6%)]\tLoss: 0.498956\n",
      "Train: [800/6252 (13%)]\tLoss: 0.500780\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.436078\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.414900\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.524340\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.345191\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.464894\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.443456\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.613097\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.451982\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.359607\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.400075\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.512321\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.365176\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.526527\n",
      "Epoch: 17/200. Train set: Average loss: 0.4641\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.346643\n",
      "Train: [800/6252 (13%)]\tLoss: 0.559731\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.621926\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.361114\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.551389\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.765024\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.647755\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.395956\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.409303\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.548228\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.680629\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.483624\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.449999\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.554427\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.277690\n",
      "Epoch: 18/200. Train set: Average loss: 0.5148\n",
      "Train: [0/6252 (0%)]\tLoss: 0.975525\n",
      "Train: [400/6252 (6%)]\tLoss: 0.529353\n",
      "Train: [800/6252 (13%)]\tLoss: 0.458466\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.603346\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.478240\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.245294\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.371827\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.599777\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.299527\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.498549\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.446544\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.388751\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.509381\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.352192\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.639062\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.448029\n",
      "Epoch: 19/200. Train set: Average loss: 0.4649\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.368269\n",
      "Train: [800/6252 (13%)]\tLoss: 0.553806\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.524063\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.697928\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.553158\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.398379\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.563770\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.503530\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.548769\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.595216\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.841426\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.354037\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.351720\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.506035\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.363925\n",
      "Epoch: 20/200. Train set: Average loss: 0.5066\n",
      "Train: [0/6252 (0%)]\tLoss: 1.048752\n",
      "Train: [400/6252 (6%)]\tLoss: 0.233448\n",
      "Train: [800/6252 (13%)]\tLoss: 0.543491\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.554370\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.512543\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.508612\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.579069\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.357188\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.518613\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.388124\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.646383\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.726802\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.539153\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.590538\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.542391\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.593349\n",
      "Epoch: 21/200. Train set: Average loss: 0.5170\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.539753\n",
      "Train: [800/6252 (13%)]\tLoss: 0.446490\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.553249\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.704487\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.444437\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.760266\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.246632\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.797289\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.303943\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.540411\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.457526\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.598542\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.425858\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.503637\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.507427\n",
      "Epoch: 22/200. Train set: Average loss: 0.5241\n",
      "Train: [0/6252 (0%)]\tLoss: 0.891754\n",
      "Train: [400/6252 (6%)]\tLoss: 0.562691\n",
      "Train: [800/6252 (13%)]\tLoss: 0.604512\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.468712\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.487652\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.454688\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.681539\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.388482\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.545605\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.620440\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.599251\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.365226\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.502063\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.531091\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.368340\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.406387\n",
      "Epoch: 23/200. Train set: Average loss: 0.5039\n",
      "Train: [0/6252 (0%)]\tLoss: 0.964081\n",
      "Train: [400/6252 (6%)]\tLoss: 0.456167\n",
      "Train: [800/6252 (13%)]\tLoss: 0.399282\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.355692\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.258412\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.668481\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.458290\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.426942\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.559291\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.386180\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.467211\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.602637\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.505418\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.390494\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.498509\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.713881\n",
      "Epoch: 24/200. Train set: Average loss: 0.4696\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.459669\n",
      "Train: [800/6252 (13%)]\tLoss: 0.331656\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.393755\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.502798\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.522609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [2400/6252 (38%)]\tLoss: 0.639088\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.563971\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.325290\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.573704\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.592844\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.680810\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.548997\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.286764\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.435463\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.507944\n",
      "Epoch: 25/200. Train set: Average loss: 0.4899\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.384645\n",
      "Train: [800/6252 (13%)]\tLoss: 0.511435\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.444272\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.478886\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.561205\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.700151\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.600936\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.400192\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.552779\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.407003\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.453003\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.529972\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.525518\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.503941\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.340931\n",
      "Epoch: 26/200. Train set: Average loss: 0.4941\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.557494\n",
      "Train: [800/6252 (13%)]\tLoss: 0.606488\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.517606\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.524585\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.460541\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.647445\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.620109\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.459014\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.300182\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.532197\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.293612\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.434874\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.556029\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.408256\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.568705\n",
      "Epoch: 27/200. Train set: Average loss: 0.5004\n",
      "Train: [0/6252 (0%)]\tLoss: 0.973434\n",
      "Train: [400/6252 (6%)]\tLoss: 0.407780\n",
      "Train: [800/6252 (13%)]\tLoss: 0.566277\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.483075\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.450531\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.406632\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.527877\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.531927\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.655642\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.464592\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.532644\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.456908\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.540151\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.365798\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.696236\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.326536\n",
      "Epoch: 28/200. Train set: Average loss: 0.4906\n",
      "Train: [0/6252 (0%)]\tLoss: 0.835114\n",
      "Train: [400/6252 (6%)]\tLoss: 0.490610\n",
      "Train: [800/6252 (13%)]\tLoss: 0.490717\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.339092\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.659581\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.574240\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.438843\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.655528\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.392381\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.591323\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.300760\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.623450\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.521659\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.433634\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.439272\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.380711\n",
      "Epoch: 29/200. Train set: Average loss: 0.4971\n",
      "Train: [0/6252 (0%)]\tLoss: 0.841339\n",
      "Train: [400/6252 (6%)]\tLoss: 0.415085\n",
      "Train: [800/6252 (13%)]\tLoss: 0.611532\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.583575\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.543594\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.590314\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.327425\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.448877\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.385447\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.526720\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.707046\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.724406\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.516582\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.567532\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.537014\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.387585\n",
      "Epoch: 30/200. Train set: Average loss: 0.5215\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.512520\n",
      "Train: [800/6252 (13%)]\tLoss: 0.505129\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.467417\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.601344\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.310287\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.428148\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.327297\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.454778\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.701077\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.343636\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.459931\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.594694\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.708888\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.678233\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.610233\n",
      "Epoch: 31/200. Train set: Average loss: 0.5164\n",
      "Train: [0/6252 (0%)]\tLoss: 0.931641\n",
      "Train: [400/6252 (6%)]\tLoss: 0.531760\n",
      "Train: [800/6252 (13%)]\tLoss: 0.570265\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.438804\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.523623\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.365504\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.487001\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.667725\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.440481\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.581393\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.519498\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.447367\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.608135\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.428420\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.428193\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.707718\n",
      "Epoch: 32/200. Train set: Average loss: 0.5138\n",
      "Train: [0/6252 (0%)]\tLoss: 0.964111\n",
      "Train: [400/6252 (6%)]\tLoss: 0.404275\n",
      "Train: [800/6252 (13%)]\tLoss: 0.291251\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.364674\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.491859\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.543584\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.762843\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.458014\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.547464\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.563129\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.445009\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.386203\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.420514\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.716684\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.600138\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.606573\n",
      "Epoch: 33/200. Train set: Average loss: 0.4982\n",
      "Train: [0/6252 (0%)]\tLoss: 1.098007\n",
      "Train: [400/6252 (6%)]\tLoss: 0.198692\n",
      "Train: [800/6252 (13%)]\tLoss: 0.510023\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.509571\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.664360\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.490089\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.765142\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.693847\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.662548\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.544778\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.365463\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.460862\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.670369\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.649961\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.446347\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.476517\n",
      "Epoch: 34/200. Train set: Average loss: 0.5388\n",
      "Train: [0/6252 (0%)]\tLoss: 1.104630\n",
      "Train: [400/6252 (6%)]\tLoss: 0.588043\n",
      "Train: [800/6252 (13%)]\tLoss: 0.501377\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.442935\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.502901\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.815969\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.361588\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.448211\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.644402\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.611098\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.414857\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.736139\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.549683\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.554693\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.554090\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.474552\n",
      "Epoch: 35/200. Train set: Average loss: 0.5527\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.537006\n",
      "Train: [800/6252 (13%)]\tLoss: 0.409235\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.346221\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.644417\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.486918\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.437875\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.531832\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.398265\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.495112\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.351165\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.608353\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.375960\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.576951\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.619924\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.553527\n",
      "Epoch: 36/200. Train set: Average loss: 0.4842\n",
      "Train: [0/6252 (0%)]\tLoss: 0.901291\n",
      "Train: [400/6252 (6%)]\tLoss: 0.406980\n",
      "Train: [800/6252 (13%)]\tLoss: 0.475182\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.646229\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.577530\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.522113\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.557420\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.644625\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.665551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [3600/6252 (58%)]\tLoss: 0.299438\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.452754\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.205312\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.379205\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.584254\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.393715\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.754017\n",
      "Epoch: 37/200. Train set: Average loss: 0.4987\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.400023\n",
      "Train: [800/6252 (13%)]\tLoss: 0.529344\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.768471\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.580812\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.555534\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.451215\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.428727\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.600802\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.574952\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.613233\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.515968\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.683035\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.486372\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.456754\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.579926\n",
      "Epoch: 38/200. Train set: Average loss: 0.5410\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.512862\n",
      "Train: [800/6252 (13%)]\tLoss: 0.367695\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.451178\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.466478\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.477052\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.526349\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.522462\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.526029\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.450976\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.521677\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.471996\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.667152\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.445492\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.548167\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.578902\n",
      "Epoch: 39/200. Train set: Average loss: 0.4976\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.634969\n",
      "Train: [800/6252 (13%)]\tLoss: 0.562170\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.334722\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.510563\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.500342\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.583771\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.301134\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.507481\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.406504\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.625729\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.496831\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.226385\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.675263\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.698253\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.503545\n",
      "Epoch: 40/200. Train set: Average loss: 0.4964\n",
      "Train: [0/6252 (0%)]\tLoss: 1.097015\n",
      "Train: [400/6252 (6%)]\tLoss: 0.441059\n",
      "Train: [800/6252 (13%)]\tLoss: 0.616428\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.554950\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.601872\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.605796\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.539666\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.547922\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.781348\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.456047\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.576944\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.613599\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.399999\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.393051\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.400970\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.526896\n",
      "Epoch: 41/200. Train set: Average loss: 0.5245\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.435668\n",
      "Train: [800/6252 (13%)]\tLoss: 0.576821\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.391644\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.535612\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.641839\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.351207\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.564288\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.412301\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.505858\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.578556\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.480445\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.394118\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.565930\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.413682\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.311444\n",
      "Epoch: 42/200. Train set: Average loss: 0.4842\n",
      "Train: [0/6252 (0%)]\tLoss: 0.990204\n",
      "Train: [400/6252 (6%)]\tLoss: 0.448414\n",
      "Train: [800/6252 (13%)]\tLoss: 0.558748\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.746352\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.552207\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.475195\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.631823\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.399188\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.401331\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.654912\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.246985\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.448170\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.423459\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.330094\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.659107\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.500962\n",
      "Epoch: 43/200. Train set: Average loss: 0.5038\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.542580\n",
      "Train: [800/6252 (13%)]\tLoss: 0.573268\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.475334\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.387735\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.402272\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.511396\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.493147\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.596003\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.506593\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.534859\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.346412\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.630638\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.496441\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.573698\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.447841\n",
      "Epoch: 44/200. Train set: Average loss: 0.4956\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.488748\n",
      "Train: [800/6252 (13%)]\tLoss: 0.497248\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.457635\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.691918\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.465467\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.569604\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.531532\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.438026\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.399939\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.396933\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.420047\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.334709\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.691657\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.347566\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.444146\n",
      "Epoch: 45/200. Train set: Average loss: 0.4737\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.614229\n",
      "Train: [800/6252 (13%)]\tLoss: 0.589122\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.472574\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.381798\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.357360\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.500319\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.656365\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.677034\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.252570\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.552353\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.301999\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.499797\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.537588\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.763600\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.461362\n",
      "Epoch: 46/200. Train set: Average loss: 0.5058\n",
      "Train: [0/6252 (0%)]\tLoss: 0.949524\n",
      "Train: [400/6252 (6%)]\tLoss: 0.441639\n",
      "Train: [800/6252 (13%)]\tLoss: 0.433004\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.716829\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.671529\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.459013\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.524076\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.452516\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.412985\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.555341\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.439488\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.636686\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.448219\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.491114\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.458144\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.348367\n",
      "Epoch: 47/200. Train set: Average loss: 0.5036\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.527532\n",
      "Train: [800/6252 (13%)]\tLoss: 0.474778\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.177406\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.646956\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.538166\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.515162\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.391296\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.415983\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.447299\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.325468\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.559468\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.352874\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.565141\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.526805\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.616267\n",
      "Epoch: 48/200. Train set: Average loss: 0.4650\n",
      "Train: [0/6252 (0%)]\tLoss: 1.027771\n",
      "Train: [400/6252 (6%)]\tLoss: 0.453675\n",
      "Train: [800/6252 (13%)]\tLoss: 0.511924\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.616642\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.530136\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.405597\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.462359\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.464986\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.696954\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.318410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [4000/6252 (64%)]\tLoss: 0.502581\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.508517\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.562081\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.445468\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.378425\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.704729\n",
      "Epoch: 49/200. Train set: Average loss: 0.5056\n",
      "Train: [0/6252 (0%)]\tLoss: 0.941849\n",
      "Train: [400/6252 (6%)]\tLoss: 0.580579\n",
      "Train: [800/6252 (13%)]\tLoss: 0.535346\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.384096\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.590653\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.452908\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.603571\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.563423\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.485242\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.544461\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.613620\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.508620\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.667783\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.651287\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.497493\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.455558\n",
      "Epoch: 50/200. Train set: Average loss: 0.5325\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.438916\n",
      "Train: [800/6252 (13%)]\tLoss: 0.356486\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.386573\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.299998\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.641127\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.708618\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.337178\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.394511\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.784732\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.709085\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.521255\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.495411\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.688288\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.398297\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.397753\n",
      "Epoch: 51/200. Train set: Average loss: 0.4987\n",
      "Train: [0/6252 (0%)]\tLoss: 1.096710\n",
      "Train: [400/6252 (6%)]\tLoss: 0.514880\n",
      "Train: [800/6252 (13%)]\tLoss: 0.539659\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.498769\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.442672\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.586705\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.489603\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.489985\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.412664\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.378303\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.459251\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.355325\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.258848\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.542179\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.552377\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.498465\n",
      "Epoch: 52/200. Train set: Average loss: 0.4710\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.403307\n",
      "Train: [800/6252 (13%)]\tLoss: 0.362394\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.468663\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.689123\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.293473\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.509600\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.572077\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.562277\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.407094\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.733244\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.285200\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.556725\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.677625\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.519279\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.523680\n",
      "Epoch: 53/200. Train set: Average loss: 0.5031\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.636370\n",
      "Train: [800/6252 (13%)]\tLoss: 0.492068\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.453485\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.401714\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.633707\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.494233\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.615468\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.455520\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.668484\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.377869\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.399151\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.623360\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.495292\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.601657\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.398952\n",
      "Epoch: 54/200. Train set: Average loss: 0.5138\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.651794\n",
      "Train: [800/6252 (13%)]\tLoss: 0.673532\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.296982\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.475797\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.391872\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.732971\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.615954\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.604456\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.326578\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.501421\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.754366\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.427200\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.759084\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.517420\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.419060\n",
      "Epoch: 55/200. Train set: Average loss: 0.5396\n",
      "Train: [0/6252 (0%)]\tLoss: 0.971939\n",
      "Train: [400/6252 (6%)]\tLoss: 0.506834\n",
      "Train: [800/6252 (13%)]\tLoss: 0.502079\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.348233\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.489063\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.639645\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.462585\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.506128\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.622425\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.537442\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.493114\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.441970\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.395335\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.349107\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.411460\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.596697\n",
      "Epoch: 56/200. Train set: Average loss: 0.4883\n",
      "Train: [0/6252 (0%)]\tLoss: 1.073471\n",
      "Train: [400/6252 (6%)]\tLoss: 0.557484\n",
      "Train: [800/6252 (13%)]\tLoss: 0.444656\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.549257\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.488729\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.401242\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.320197\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.321788\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.678214\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.470709\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.721794\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.518473\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.505401\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.434348\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.561604\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.422874\n",
      "Epoch: 57/200. Train set: Average loss: 0.4892\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.384323\n",
      "Train: [800/6252 (13%)]\tLoss: 0.646032\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.497754\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.615005\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.478763\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.492334\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.457677\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.587569\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.667326\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.637495\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.542747\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.556371\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.449535\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.353474\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.257225\n",
      "Epoch: 58/200. Train set: Average loss: 0.5021\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.441291\n",
      "Train: [800/6252 (13%)]\tLoss: 0.604793\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.588923\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.337243\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.290008\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.670329\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.547221\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.380215\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.615187\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.577577\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.446659\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.544524\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.430196\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.393378\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.461182\n",
      "Epoch: 59/200. Train set: Average loss: 0.4853\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.525400\n",
      "Train: [800/6252 (13%)]\tLoss: 0.569136\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.496764\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.708205\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.403114\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.442678\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.478255\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.491975\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.455443\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.550666\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.531335\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.362634\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.387360\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.368401\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.571676\n",
      "Epoch: 60/200. Train set: Average loss: 0.4885\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.436443\n",
      "Train: [800/6252 (13%)]\tLoss: 0.248908\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.647211\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.823889\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.484878\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.609239\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.367634\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.650406\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.445545\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.448936\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.426757\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.595718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [5200/6252 (83%)]\tLoss: 0.530579\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.677194\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.427908\n",
      "Epoch: 61/200. Train set: Average loss: 0.5219\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.549445\n",
      "Train: [800/6252 (13%)]\tLoss: 0.537772\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.669918\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.440978\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.536575\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.775349\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.438991\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.620958\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.468446\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.495308\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.477761\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.602408\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.481942\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.434350\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.377689\n",
      "Epoch: 62/200. Train set: Average loss: 0.5186\n",
      "Train: [0/6252 (0%)]\tLoss: 0.981812\n",
      "Train: [400/6252 (6%)]\tLoss: 0.508029\n",
      "Train: [800/6252 (13%)]\tLoss: 0.350608\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.577205\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.354263\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.495173\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.708923\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.424289\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.458109\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.455874\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.392831\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.663138\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.572048\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.403041\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.578654\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.637647\n",
      "Epoch: 63/200. Train set: Average loss: 0.5021\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.302143\n",
      "Train: [800/6252 (13%)]\tLoss: 0.558515\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.336993\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.444153\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.223672\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.553706\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.696999\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.267490\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.722987\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.713940\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.693832\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.423819\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.560410\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.582706\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.470316\n",
      "Epoch: 64/200. Train set: Average loss: 0.5043\n",
      "Train: [0/6252 (0%)]\tLoss: 0.935669\n",
      "Train: [400/6252 (6%)]\tLoss: 0.367337\n",
      "Train: [800/6252 (13%)]\tLoss: 0.565287\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.666358\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.548053\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.544817\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.545811\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.558551\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.446173\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.397104\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.388573\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.537389\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.356930\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.590854\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.389477\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.459656\n",
      "Epoch: 65/200. Train set: Average loss: 0.4870\n",
      "Train: [0/6252 (0%)]\tLoss: 1.097481\n",
      "Train: [400/6252 (6%)]\tLoss: 0.553338\n",
      "Train: [800/6252 (13%)]\tLoss: 0.574640\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.566958\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.345970\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.508715\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.666289\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.478040\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.527570\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.361407\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.658273\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.624094\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.603116\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.413560\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.548038\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.511270\n",
      "Epoch: 66/200. Train set: Average loss: 0.5289\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.213557\n",
      "Train: [800/6252 (13%)]\tLoss: 0.539729\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.571935\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.339410\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.697764\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.463155\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.425617\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.418114\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.496428\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.502444\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.556694\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.405812\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.525537\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.716891\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.692110\n",
      "Epoch: 67/200. Train set: Average loss: 0.5106\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.517927\n",
      "Train: [800/6252 (13%)]\tLoss: 0.563386\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.497619\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.502554\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.459358\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.500291\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.570100\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.199911\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.488145\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.402841\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.595414\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.431296\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.446705\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.539900\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.763662\n",
      "Epoch: 68/200. Train set: Average loss: 0.5008\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.404296\n",
      "Train: [800/6252 (13%)]\tLoss: 0.587669\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.466961\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.494094\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.537769\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.473258\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.630108\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.569833\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.289622\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.647843\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.487589\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.413020\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.672338\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.352254\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.548088\n",
      "Epoch: 69/200. Train set: Average loss: 0.5051\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.513642\n",
      "Train: [800/6252 (13%)]\tLoss: 0.732069\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.586992\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.702776\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.409562\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.686630\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.368510\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.364636\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.644580\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.709973\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.477010\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.488230\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.476621\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.386961\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.546220\n",
      "Epoch: 70/200. Train set: Average loss: 0.5330\n",
      "Train: [0/6252 (0%)]\tLoss: 0.966385\n",
      "Train: [400/6252 (6%)]\tLoss: 0.406789\n",
      "Train: [800/6252 (13%)]\tLoss: 0.471546\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.540753\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.583772\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.482143\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.306944\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.388086\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.642756\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.498804\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.539717\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.347915\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.589179\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.302804\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.513851\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.504992\n",
      "Epoch: 71/200. Train set: Average loss: 0.4742\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.309161\n",
      "Train: [800/6252 (13%)]\tLoss: 0.401071\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.409940\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.507822\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.431423\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.444968\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.510965\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.484841\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.492488\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.510231\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.653578\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.441141\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.502328\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.728369\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.392941\n",
      "Epoch: 72/200. Train set: Average loss: 0.4838\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.522542\n",
      "Train: [800/6252 (13%)]\tLoss: 0.747406\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.589001\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.388713\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.540459\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.401511\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.558730\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.449139\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.477204\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.590313\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.540248\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.512085\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.396189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [5600/6252 (89%)]\tLoss: 0.583728\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.347368\n",
      "Epoch: 73/200. Train set: Average loss: 0.5078\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.346325\n",
      "Train: [800/6252 (13%)]\tLoss: 0.550336\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.636560\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.538517\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.433374\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.586798\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.705843\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.494569\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.503067\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.687471\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.580726\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.513477\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.547668\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.586000\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.508030\n",
      "Epoch: 74/200. Train set: Average loss: 0.5407\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.644246\n",
      "Train: [800/6252 (13%)]\tLoss: 0.648436\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.355862\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.448676\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.591653\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.293166\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.577256\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.467107\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.554908\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.707953\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.423903\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.553706\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.295849\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.400222\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.412498\n",
      "Epoch: 75/200. Train set: Average loss: 0.4954\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.502407\n",
      "Train: [800/6252 (13%)]\tLoss: 0.486877\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.540493\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.463176\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.502713\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.399952\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.295757\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.582155\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.690173\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.562831\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.485684\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.654558\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.664937\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.243284\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.585862\n",
      "Epoch: 76/200. Train set: Average loss: 0.5015\n",
      "Train: [0/6252 (0%)]\tLoss: 1.011169\n",
      "Train: [400/6252 (6%)]\tLoss: 0.343555\n",
      "Train: [800/6252 (13%)]\tLoss: 0.496086\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.479609\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.533517\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.578033\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.487142\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.457851\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.511864\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.653771\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.367167\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.445143\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.507614\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.487364\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.647574\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.307533\n",
      "Epoch: 77/200. Train set: Average loss: 0.4938\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.645133\n",
      "Train: [800/6252 (13%)]\tLoss: 0.576831\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.497270\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.425236\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.539755\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.349865\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.336749\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.469921\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.515690\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.508475\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.643331\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.351989\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.714021\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.680137\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.600218\n",
      "Epoch: 78/200. Train set: Average loss: 0.5180\n",
      "Train: [0/6252 (0%)]\tLoss: 0.997650\n",
      "Train: [400/6252 (6%)]\tLoss: 0.446096\n",
      "Train: [800/6252 (13%)]\tLoss: 0.587718\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.451836\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.509753\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.484625\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.462499\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.510452\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.582345\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.538044\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.464474\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.644436\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.500352\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.526302\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.310788\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.426975\n",
      "Epoch: 79/200. Train set: Average loss: 0.4983\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.538434\n",
      "Train: [800/6252 (13%)]\tLoss: 0.504875\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.454567\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.303787\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.336859\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.573652\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.391824\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.484456\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.404562\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.561271\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.264916\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.654905\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.677438\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.488934\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.249541\n",
      "Epoch: 80/200. Train set: Average loss: 0.4494\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.639240\n",
      "Train: [800/6252 (13%)]\tLoss: 0.437040\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.563720\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.525184\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.740595\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.348360\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.554599\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.445035\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.206631\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.644351\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.339013\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.504494\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.595519\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.534238\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.461482\n",
      "Epoch: 81/200. Train set: Average loss: 0.4982\n",
      "Train: [0/6252 (0%)]\tLoss: 0.934357\n",
      "Train: [400/6252 (6%)]\tLoss: 0.386372\n",
      "Train: [800/6252 (13%)]\tLoss: 0.428603\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.698766\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.506500\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.643913\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.615739\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.356316\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.407345\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.523980\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.621741\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.390563\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.433390\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.650293\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.469571\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.499281\n",
      "Epoch: 82/200. Train set: Average loss: 0.5100\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.303159\n",
      "Train: [800/6252 (13%)]\tLoss: 0.575964\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.466779\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.658912\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.463193\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.587263\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.533672\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.455811\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.268604\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.393501\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.586497\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.557638\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.405173\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.584337\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.547823\n",
      "Epoch: 83/200. Train set: Average loss: 0.4948\n",
      "Train: [0/6252 (0%)]\tLoss: 1.005463\n",
      "Train: [400/6252 (6%)]\tLoss: 0.335730\n",
      "Train: [800/6252 (13%)]\tLoss: 0.557114\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.345304\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.561886\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.561126\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.381269\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.627085\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.502209\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.442209\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.350687\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.644230\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.566257\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.500401\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.548267\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.498708\n",
      "Epoch: 84/200. Train set: Average loss: 0.4965\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.285722\n",
      "Train: [800/6252 (13%)]\tLoss: 0.424284\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.567562\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.398234\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.400653\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.482026\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.439165\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.488950\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.471859\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.500112\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.483723\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.697149\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.505410\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.654210\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.711995\n",
      "Epoch: 85/200. Train set: Average loss: 0.5026\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [400/6252 (6%)]\tLoss: 0.477695\n",
      "Train: [800/6252 (13%)]\tLoss: 0.540185\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.448852\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.379137\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.549184\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.478716\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.590693\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.374679\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.493890\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.649374\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.413808\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.514544\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.426702\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.498663\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.696186\n",
      "Epoch: 86/200. Train set: Average loss: 0.4975\n",
      "Train: [0/6252 (0%)]\tLoss: 0.934036\n",
      "Train: [400/6252 (6%)]\tLoss: 0.518299\n",
      "Train: [800/6252 (13%)]\tLoss: 0.492269\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.620575\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.312808\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.406143\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.441484\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.488194\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.402283\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.461972\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.472435\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.633765\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.527329\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.454287\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.846718\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.537813\n",
      "Epoch: 87/200. Train set: Average loss: 0.5189\n",
      "Train: [0/6252 (0%)]\tLoss: 1.043045\n",
      "Train: [400/6252 (6%)]\tLoss: 0.523188\n",
      "Train: [800/6252 (13%)]\tLoss: 0.535072\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.400789\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.493277\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.358281\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.495930\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.640905\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.513636\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.558279\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.407295\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.440329\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.456959\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.615110\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.544064\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.460329\n",
      "Epoch: 88/200. Train set: Average loss: 0.4914\n",
      "Train: [0/6252 (0%)]\tLoss: 0.771523\n",
      "Train: [400/6252 (6%)]\tLoss: 0.593722\n",
      "Train: [800/6252 (13%)]\tLoss: 0.506452\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.428490\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.437555\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.553571\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.438739\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.449320\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.549437\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.428269\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.578645\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.448302\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.560567\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.442508\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.400706\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.438812\n",
      "Epoch: 89/200. Train set: Average loss: 0.4929\n",
      "Train: [0/6252 (0%)]\tLoss: 1.022232\n",
      "Train: [400/6252 (6%)]\tLoss: 0.386504\n",
      "Train: [800/6252 (13%)]\tLoss: 0.503021\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.496672\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.558241\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.421310\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.697502\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.539694\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.424491\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.670453\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.484388\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.439298\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.499552\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.606520\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.617455\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.546648\n",
      "Epoch: 90/200. Train set: Average loss: 0.5230\n",
      "Train: [0/6252 (0%)]\tLoss: 0.925323\n",
      "Train: [400/6252 (6%)]\tLoss: 0.339281\n",
      "Train: [800/6252 (13%)]\tLoss: 0.440960\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.691833\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.403700\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.439028\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.315246\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.538476\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.563498\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.689381\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.628819\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.542951\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.382166\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.809509\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.462577\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.275775\n",
      "Epoch: 91/200. Train set: Average loss: 0.4991\n",
      "Train: [0/6252 (0%)]\tLoss: 1.050995\n",
      "Train: [400/6252 (6%)]\tLoss: 0.427386\n",
      "Train: [800/6252 (13%)]\tLoss: 0.426536\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.454564\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.364407\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.579105\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.696997\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.279153\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.418314\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.300233\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.674415\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.409460\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.535608\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.597706\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.446507\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.450509\n",
      "Epoch: 92/200. Train set: Average loss: 0.4833\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.515519\n",
      "Train: [800/6252 (13%)]\tLoss: 0.509987\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.649104\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.442074\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.548436\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.580221\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.555004\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.495771\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.633878\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.341939\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.635513\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.350750\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.480136\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.316727\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.400222\n",
      "Epoch: 93/200. Train set: Average loss: 0.4897\n",
      "Train: [0/6252 (0%)]\tLoss: 0.930298\n",
      "Train: [400/6252 (6%)]\tLoss: 0.398884\n",
      "Train: [800/6252 (13%)]\tLoss: 0.519438\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.539946\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.397954\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.606651\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.443815\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.658557\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.581419\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.670135\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.397947\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.582108\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.530270\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.541965\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.444775\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.580897\n",
      "Epoch: 94/200. Train set: Average loss: 0.5143\n",
      "Train: [0/6252 (0%)]\tLoss: 1.030884\n",
      "Train: [400/6252 (6%)]\tLoss: 0.495282\n",
      "Train: [800/6252 (13%)]\tLoss: 0.490831\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.554384\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.658027\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.409119\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.467227\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.493128\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.628289\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.355713\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.805176\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.346111\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.585812\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.358572\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.402494\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.303479\n",
      "Epoch: 95/200. Train set: Average loss: 0.5027\n",
      "Train: [0/6252 (0%)]\tLoss: 1.042068\n",
      "Train: [400/6252 (6%)]\tLoss: 0.480176\n",
      "Train: [800/6252 (13%)]\tLoss: 0.495879\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.252353\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.606657\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.455163\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.399603\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.392640\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.310478\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.700926\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.553964\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.455185\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.459293\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.606142\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.570229\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.540086\n",
      "Epoch: 96/200. Train set: Average loss: 0.4993\n",
      "Train: [0/6252 (0%)]\tLoss: 0.900375\n",
      "Train: [400/6252 (6%)]\tLoss: 0.645744\n",
      "Train: [800/6252 (13%)]\tLoss: 0.512344\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.633223\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.481696\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.354011\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.404661\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.421666\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.599528\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.500357\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.463071\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.543227\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.361638\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.595258\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.436133\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.470544\n",
      "Epoch: 97/200. Train set: Average loss: 0.4977\n",
      "Train: [0/6252 (0%)]\tLoss: 0.825043\n",
      "Train: [400/6252 (6%)]\tLoss: 0.772917\n",
      "Train: [800/6252 (13%)]\tLoss: 0.300626\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.508068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [1600/6252 (26%)]\tLoss: 0.586282\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.369702\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.465703\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.622297\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.501200\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.533493\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.435181\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.497336\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.584876\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.486797\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.526058\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.489552\n",
      "Epoch: 98/200. Train set: Average loss: 0.5102\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.341108\n",
      "Train: [800/6252 (13%)]\tLoss: 0.646307\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.543026\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.629020\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.452011\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.538669\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.680292\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.761430\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.410426\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.713393\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.469368\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.608306\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.747036\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.406114\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.651437\n",
      "Epoch: 99/200. Train set: Average loss: 0.5656\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.564727\n",
      "Train: [800/6252 (13%)]\tLoss: 0.516152\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.608729\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.498225\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.665434\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.668404\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.407689\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.456689\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.562316\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.503169\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.477645\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.453193\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.598309\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.558161\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.295413\n",
      "Epoch: 100/200. Train set: Average loss: 0.5163\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.546679\n",
      "Train: [800/6252 (13%)]\tLoss: 0.564162\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.407099\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.448333\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.477431\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.588331\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.460327\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.390836\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.513995\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.630902\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.391024\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.510210\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.458166\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.496928\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.451601\n",
      "Epoch: 101/200. Train set: Average loss: 0.4823\n",
      "Train: [0/6252 (0%)]\tLoss: 1.143509\n",
      "Train: [400/6252 (6%)]\tLoss: 0.482693\n",
      "Train: [800/6252 (13%)]\tLoss: 0.634739\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.555441\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.340560\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.471352\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.573575\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.450353\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.395387\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.465524\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.448114\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.401800\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.573125\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.406118\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.376890\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.423703\n",
      "Epoch: 102/200. Train set: Average loss: 0.4803\n",
      "Train: [0/6252 (0%)]\tLoss: 1.066788\n",
      "Train: [400/6252 (6%)]\tLoss: 0.596369\n",
      "Train: [800/6252 (13%)]\tLoss: 0.396962\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.449241\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.485253\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.484210\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.596006\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.312749\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.590836\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.474011\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.587645\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.588815\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.562451\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.608392\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.581463\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.654481\n",
      "Epoch: 103/200. Train set: Average loss: 0.5305\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.445846\n",
      "Train: [800/6252 (13%)]\tLoss: 0.573563\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.297469\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.416016\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.571495\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.492327\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.595628\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.568741\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.400028\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.560788\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.456267\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.605117\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.708960\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.501298\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.449738\n",
      "Epoch: 104/200. Train set: Average loss: 0.5014\n",
      "Train: [0/6252 (0%)]\tLoss: 1.008972\n",
      "Train: [400/6252 (6%)]\tLoss: 0.303828\n",
      "Train: [800/6252 (13%)]\tLoss: 0.679663\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.644742\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.496011\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.260914\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.426003\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.423180\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.466578\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.423225\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.358708\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.650928\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.712497\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.540999\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.664530\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.511234\n",
      "Epoch: 105/200. Train set: Average loss: 0.5096\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.382323\n",
      "Train: [800/6252 (13%)]\tLoss: 0.483595\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.673072\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.352486\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.512234\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.407402\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.619949\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.457024\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.531753\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.424810\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.724226\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.549843\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.423189\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.533021\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.555743\n",
      "Epoch: 106/200. Train set: Average loss: 0.5186\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.489932\n",
      "Train: [800/6252 (13%)]\tLoss: 0.555045\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.297732\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.655727\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.612320\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.506139\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.525946\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.474476\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.350564\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.355230\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.594463\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.603388\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.489308\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.447502\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.296204\n",
      "Epoch: 107/200. Train set: Average loss: 0.4892\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.346073\n",
      "Train: [800/6252 (13%)]\tLoss: 0.358995\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.671807\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.579321\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.654239\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.553118\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.501733\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.370993\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.418805\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.680483\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.633611\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.594101\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.386462\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.282846\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.442389\n",
      "Epoch: 108/200. Train set: Average loss: 0.4969\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.734693\n",
      "Train: [800/6252 (13%)]\tLoss: 0.502825\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.446651\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.528148\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.560520\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.432533\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.482577\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.364018\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.384142\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.523488\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.491451\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.381117\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.573458\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.559822\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.705653\n",
      "Epoch: 109/200. Train set: Average loss: 0.5123\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.458596\n",
      "Train: [800/6252 (13%)]\tLoss: 0.450378\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.639176\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.529014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [2000/6252 (32%)]\tLoss: 0.614717\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.582672\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.588403\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.574676\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.546445\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.600630\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.419308\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.402717\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.595875\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.493659\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.407527\n",
      "Epoch: 110/200. Train set: Average loss: 0.5243\n",
      "Train: [0/6252 (0%)]\tLoss: 0.994995\n",
      "Train: [400/6252 (6%)]\tLoss: 0.538591\n",
      "Train: [800/6252 (13%)]\tLoss: 0.414364\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.518990\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.545876\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.403378\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.756781\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.398618\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.679449\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.544195\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.532169\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.583114\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.544724\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.664594\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.689801\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.578589\n",
      "Epoch: 111/200. Train set: Average loss: 0.5545\n",
      "Train: [0/6252 (0%)]\tLoss: 1.077499\n",
      "Train: [400/6252 (6%)]\tLoss: 0.297260\n",
      "Train: [800/6252 (13%)]\tLoss: 0.506573\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.403870\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.541062\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.547396\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.428592\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.507176\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.536740\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.593002\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.453571\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.489946\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.476981\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.447532\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.566588\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.484065\n",
      "Epoch: 112/200. Train set: Average loss: 0.4850\n",
      "Train: [0/6252 (0%)]\tLoss: 0.878433\n",
      "Train: [400/6252 (6%)]\tLoss: 0.560172\n",
      "Train: [800/6252 (13%)]\tLoss: 0.456058\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.652816\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.645688\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.411497\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.557402\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.533448\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.511838\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.587830\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.479508\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.523757\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.605789\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.347672\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.583109\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.406145\n",
      "Epoch: 113/200. Train set: Average loss: 0.5202\n",
      "Train: [0/6252 (0%)]\tLoss: 0.869141\n",
      "Train: [400/6252 (6%)]\tLoss: 0.410501\n",
      "Train: [800/6252 (13%)]\tLoss: 0.195286\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.380753\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.581955\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.522633\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.359289\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.640263\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.660154\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.287328\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.545044\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.565458\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.593465\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.488905\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.431245\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.532312\n",
      "Epoch: 114/200. Train set: Average loss: 0.4816\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.548330\n",
      "Train: [800/6252 (13%)]\tLoss: 0.565678\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.313426\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.546595\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.511675\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.645784\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.495809\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.337106\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.660495\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.605068\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.575441\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.548736\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.649627\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.488223\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.545345\n",
      "Epoch: 115/200. Train set: Average loss: 0.5235\n",
      "Train: [0/6252 (0%)]\tLoss: 1.103241\n",
      "Train: [400/6252 (6%)]\tLoss: 0.647940\n",
      "Train: [800/6252 (13%)]\tLoss: 0.422789\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.395264\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.535709\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.592310\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.474151\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.554441\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.356949\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.374144\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.489672\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.429051\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.489607\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.467841\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.349770\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.410985\n",
      "Epoch: 116/200. Train set: Average loss: 0.4698\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.391891\n",
      "Train: [800/6252 (13%)]\tLoss: 0.440965\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.404950\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.567697\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.592196\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.445602\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.691839\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.302586\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.720381\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.496692\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.602951\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.603222\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.659530\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.564686\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.617383\n",
      "Epoch: 117/200. Train set: Average loss: 0.5428\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.502455\n",
      "Train: [800/6252 (13%)]\tLoss: 0.761558\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.556068\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.445462\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.621941\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.581716\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.612168\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.495745\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.308533\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.468179\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.649583\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.292733\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.501078\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.518626\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.506330\n",
      "Epoch: 118/200. Train set: Average loss: 0.5061\n",
      "Train: [0/6252 (0%)]\tLoss: 0.809937\n",
      "Train: [400/6252 (6%)]\tLoss: 0.541863\n",
      "Train: [800/6252 (13%)]\tLoss: 0.673947\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.451704\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.519854\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.583216\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.437967\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.618363\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.399555\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.455351\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.297384\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.305507\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.552484\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.503004\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.352529\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.750262\n",
      "Epoch: 119/200. Train set: Average loss: 0.5067\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.453496\n",
      "Train: [800/6252 (13%)]\tLoss: 0.598583\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.380453\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.480364\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.561035\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.489980\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.513876\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.618988\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.501431\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.398071\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.474544\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.623330\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.493902\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.355119\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.558527\n",
      "Epoch: 120/200. Train set: Average loss: 0.4953\n",
      "Train: [0/6252 (0%)]\tLoss: 0.892883\n",
      "Train: [400/6252 (6%)]\tLoss: 0.552508\n",
      "Train: [800/6252 (13%)]\tLoss: 0.505794\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.653936\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.441743\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.355862\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.415461\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.698091\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.293542\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.437984\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.412624\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.285374\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.546233\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.452026\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.656380\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.448368\n",
      "Epoch: 121/200. Train set: Average loss: 0.4727\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.583058\n",
      "Train: [800/6252 (13%)]\tLoss: 0.354545\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.493552\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.512730\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.432605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [2400/6252 (38%)]\tLoss: 0.521462\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.452217\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.639419\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.496522\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.395473\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.525526\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.538773\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.514092\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.595681\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.390040\n",
      "Epoch: 122/200. Train set: Average loss: 0.4851\n",
      "Train: [0/6252 (0%)]\tLoss: 1.009186\n",
      "Train: [400/6252 (6%)]\tLoss: 0.500412\n",
      "Train: [800/6252 (13%)]\tLoss: 0.576077\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.612286\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.590814\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.415020\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.394866\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.299254\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.681430\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.412000\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.389476\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.285662\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.621420\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.575303\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.448684\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.607704\n",
      "Epoch: 123/200. Train set: Average loss: 0.4864\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.344369\n",
      "Train: [800/6252 (13%)]\tLoss: 0.583123\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.699952\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.459683\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.602987\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.557424\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.407589\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.453528\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.502557\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.800948\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.435813\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.353366\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.452930\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.243182\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.551174\n",
      "Epoch: 124/200. Train set: Average loss: 0.4947\n",
      "Train: [0/6252 (0%)]\tLoss: 1.109131\n",
      "Train: [400/6252 (6%)]\tLoss: 0.607478\n",
      "Train: [800/6252 (13%)]\tLoss: 0.770490\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.421778\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.467844\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.447600\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.693771\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.413257\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.455997\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.567058\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.597256\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.378612\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.550381\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.333211\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.464957\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.466980\n",
      "Epoch: 125/200. Train set: Average loss: 0.5126\n",
      "Train: [0/6252 (0%)]\tLoss: 0.950348\n",
      "Train: [400/6252 (6%)]\tLoss: 0.493362\n",
      "Train: [800/6252 (13%)]\tLoss: 0.498550\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.539242\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.724795\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.501218\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.637426\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.369881\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.402275\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.618278\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.596131\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.536769\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.496988\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.542705\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.545184\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.529070\n",
      "Epoch: 126/200. Train set: Average loss: 0.5331\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.413496\n",
      "Train: [800/6252 (13%)]\tLoss: 0.449570\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.482338\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.302957\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.488727\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.545197\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.545630\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.506777\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.722462\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.327478\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.553437\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.424183\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.487907\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.463767\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.544629\n",
      "Epoch: 127/200. Train set: Average loss: 0.4764\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.605737\n",
      "Train: [800/6252 (13%)]\tLoss: 0.503247\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.313051\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.483279\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.594975\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.641453\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.389857\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.445788\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.663947\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.250890\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.459514\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.562479\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.587760\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.602547\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.504807\n",
      "Epoch: 128/200. Train set: Average loss: 0.5126\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.291678\n",
      "Train: [800/6252 (13%)]\tLoss: 0.651619\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.503968\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.570257\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.643947\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.615520\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.502930\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.334116\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.730567\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.447279\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.304465\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.426080\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.507471\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.421879\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.682016\n",
      "Epoch: 129/200. Train set: Average loss: 0.5015\n",
      "Train: [0/6252 (0%)]\tLoss: 1.101486\n",
      "Train: [400/6252 (6%)]\tLoss: 0.341514\n",
      "Train: [800/6252 (13%)]\tLoss: 0.416483\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.390109\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.461018\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.641890\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.607318\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.637833\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.538641\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.491294\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.495055\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.621774\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.458937\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.349682\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.509031\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.494296\n",
      "Epoch: 130/200. Train set: Average loss: 0.4983\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.452528\n",
      "Train: [800/6252 (13%)]\tLoss: 0.344756\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.510975\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.408361\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.473838\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.350436\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.311379\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.389202\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.619643\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.526801\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.570669\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.687965\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.501089\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.662970\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.627407\n",
      "Epoch: 131/200. Train set: Average loss: 0.4946\n",
      "Train: [0/6252 (0%)]\tLoss: 0.969391\n",
      "Train: [400/6252 (6%)]\tLoss: 0.374529\n",
      "Train: [800/6252 (13%)]\tLoss: 0.390699\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.554315\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.535562\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.447600\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.527036\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.604995\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.599469\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.363666\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.448527\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.426389\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.457767\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.480355\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.555978\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.654123\n",
      "Epoch: 132/200. Train set: Average loss: 0.4967\n",
      "Train: [0/6252 (0%)]\tLoss: 0.995331\n",
      "Train: [400/6252 (6%)]\tLoss: 0.481853\n",
      "Train: [800/6252 (13%)]\tLoss: 0.615173\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.488654\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.481591\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.486158\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.495134\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.493686\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.687858\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.493719\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.510778\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.560550\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.634354\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.460698\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.680285\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.448662\n",
      "Epoch: 133/200. Train set: Average loss: 0.5446\n",
      "Train: [0/6252 (0%)]\tLoss: 0.989532\n",
      "Train: [400/6252 (6%)]\tLoss: 0.457973\n",
      "Train: [800/6252 (13%)]\tLoss: 0.742524\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.461021\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.292026\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.383932\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.477079\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.508667\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.495143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [3600/6252 (58%)]\tLoss: 0.498940\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.491302\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.620595\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.453059\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.450249\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.567685\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.716999\n",
      "Epoch: 134/200. Train set: Average loss: 0.5057\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.444343\n",
      "Train: [800/6252 (13%)]\tLoss: 0.511721\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.350340\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.670311\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.545548\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.457845\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.389043\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.600875\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.590706\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.522470\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.575536\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.364691\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.606168\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.434996\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.508928\n",
      "Epoch: 135/200. Train set: Average loss: 0.5027\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.378265\n",
      "Train: [800/6252 (13%)]\tLoss: 0.457790\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.686505\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.655154\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.458000\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.567572\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.437323\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.551667\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.550033\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.497375\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.763089\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.550331\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.610622\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.685417\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.666597\n",
      "Epoch: 136/200. Train set: Average loss: 0.5570\n",
      "Train: [0/6252 (0%)]\tLoss: 0.922119\n",
      "Train: [400/6252 (6%)]\tLoss: 0.201047\n",
      "Train: [800/6252 (13%)]\tLoss: 0.536721\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.600621\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.437943\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.470925\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.502747\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.633246\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.609526\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.434764\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.606102\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.642816\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.548454\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.755728\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.435981\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.735283\n",
      "Epoch: 137/200. Train set: Average loss: 0.5389\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.657150\n",
      "Train: [800/6252 (13%)]\tLoss: 0.576451\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.498705\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.610880\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.331856\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.517570\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.399613\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.397203\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.535934\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.588580\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.414805\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.570082\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.595251\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.478446\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.447732\n",
      "Epoch: 138/200. Train set: Average loss: 0.5076\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.292009\n",
      "Train: [800/6252 (13%)]\tLoss: 0.506172\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.652074\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.505299\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.553678\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.526067\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.386978\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.548057\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.505124\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.492620\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.672210\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.649382\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.548253\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.465564\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.473449\n",
      "Epoch: 139/200. Train set: Average loss: 0.5189\n",
      "Train: [0/6252 (0%)]\tLoss: 0.900604\n",
      "Train: [400/6252 (6%)]\tLoss: 0.463925\n",
      "Train: [800/6252 (13%)]\tLoss: 0.719790\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.402510\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.492226\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.388920\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.355610\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.336117\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.458188\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.443786\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.514487\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.689945\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.432771\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.505691\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.434307\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.422348\n",
      "Epoch: 140/200. Train set: Average loss: 0.4763\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.559061\n",
      "Train: [800/6252 (13%)]\tLoss: 0.557083\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.529251\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.480359\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.507627\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.461633\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.669438\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.641778\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.760897\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.445913\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.500172\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.525226\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.519445\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.566405\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.410444\n",
      "Epoch: 141/200. Train set: Average loss: 0.5427\n",
      "Train: [0/6252 (0%)]\tLoss: 0.951782\n",
      "Train: [400/6252 (6%)]\tLoss: 0.602451\n",
      "Train: [800/6252 (13%)]\tLoss: 0.505264\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.719578\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.423706\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.436420\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.657514\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.469774\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.492097\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.499021\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.444326\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.466778\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.440020\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.478528\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.551898\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.586552\n",
      "Epoch: 142/200. Train set: Average loss: 0.5288\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.346439\n",
      "Train: [800/6252 (13%)]\tLoss: 0.402472\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.360451\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.298507\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.476888\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.386495\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.728234\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.598037\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.505012\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.584336\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.512579\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.705975\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.662092\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.421016\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.562987\n",
      "Epoch: 143/200. Train set: Average loss: 0.5055\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.454868\n",
      "Train: [800/6252 (13%)]\tLoss: 0.542981\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.527213\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.610763\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.588060\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.484937\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.411881\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.315141\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.620712\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.441262\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.575075\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.622326\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.521152\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.572975\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.504287\n",
      "Epoch: 144/200. Train set: Average loss: 0.5200\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.410229\n",
      "Train: [800/6252 (13%)]\tLoss: 0.663795\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.680168\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.507337\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.521974\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.347498\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.358805\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.294626\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.576682\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.340739\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.338800\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.612936\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.427913\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.413728\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.547485\n",
      "Epoch: 145/200. Train set: Average loss: 0.4632\n",
      "Train: [0/6252 (0%)]\tLoss: 0.845673\n",
      "Train: [400/6252 (6%)]\tLoss: 0.534102\n",
      "Train: [800/6252 (13%)]\tLoss: 0.459906\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.528160\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.333105\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.699387\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.684806\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.445468\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.529128\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.661276\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.690138\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.371016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [4800/6252 (77%)]\tLoss: 0.511533\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.422143\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.355756\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.450330\n",
      "Epoch: 146/200. Train set: Average loss: 0.5138\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.449677\n",
      "Train: [800/6252 (13%)]\tLoss: 0.650202\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.589287\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.457140\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.688152\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.486300\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.408160\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.355968\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.536512\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.501761\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.536367\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.598667\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.662188\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.565395\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.498054\n",
      "Epoch: 147/200. Train set: Average loss: 0.5290\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.508643\n",
      "Train: [800/6252 (13%)]\tLoss: 0.392789\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.291390\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.585103\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.568933\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.708775\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.556155\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.387662\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.519385\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.493354\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.685911\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.408544\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.497045\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.658264\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.500073\n",
      "Epoch: 148/200. Train set: Average loss: 0.5136\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.625892\n",
      "Train: [800/6252 (13%)]\tLoss: 0.391440\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.410060\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.404173\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.604647\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.682296\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.513888\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.683599\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.493413\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.698595\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.552960\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.490204\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.671647\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.507875\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.392477\n",
      "Epoch: 149/200. Train set: Average loss: 0.5393\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.563908\n",
      "Train: [800/6252 (13%)]\tLoss: 0.389252\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.576054\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.401772\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.569630\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.403024\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.352126\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.565537\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.586215\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.661605\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.434558\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.491607\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.493351\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.344459\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.449741\n",
      "Epoch: 150/200. Train set: Average loss: 0.4876\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.593122\n",
      "Train: [800/6252 (13%)]\tLoss: 0.473463\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.649957\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.674097\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.446359\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.498037\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.450810\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.458343\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.582531\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.486185\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.604371\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.457608\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.497131\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.574698\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.440443\n",
      "Epoch: 151/200. Train set: Average loss: 0.5196\n",
      "Train: [0/6252 (0%)]\tLoss: 1.225418\n",
      "Train: [400/6252 (6%)]\tLoss: 0.479492\n",
      "Train: [800/6252 (13%)]\tLoss: 0.439511\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.445674\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.437576\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.491234\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.308559\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.424109\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.359989\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.505309\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.564995\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.554337\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.564095\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.498408\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.552527\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.763681\n",
      "Epoch: 152/200. Train set: Average loss: 0.5014\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.408777\n",
      "Train: [800/6252 (13%)]\tLoss: 0.544690\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.537476\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.411575\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.489755\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.262346\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.481848\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.694536\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.317594\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.481416\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.369026\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.441522\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.547848\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.555188\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.607141\n",
      "Epoch: 153/200. Train set: Average loss: 0.4672\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.439798\n",
      "Train: [800/6252 (13%)]\tLoss: 0.515243\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.618175\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.488597\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.654166\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.453597\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.504506\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.374370\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.341618\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.276232\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.581561\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.397706\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.617587\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.525330\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.526923\n",
      "Epoch: 154/200. Train set: Average loss: 0.4893\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.599077\n",
      "Train: [800/6252 (13%)]\tLoss: 0.418548\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.293301\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.480391\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.454517\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.453070\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.303101\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.645379\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.469913\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.450491\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.393477\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.716897\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.382703\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.823309\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.486480\n",
      "Epoch: 155/200. Train set: Average loss: 0.4896\n",
      "Train: [0/6252 (0%)]\tLoss: 0.991013\n",
      "Train: [400/6252 (6%)]\tLoss: 0.403685\n",
      "Train: [800/6252 (13%)]\tLoss: 0.518769\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.626060\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.491745\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.535775\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.379504\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.488096\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.441154\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.555471\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.762079\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.557967\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.706067\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.412097\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.490593\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.619640\n",
      "Epoch: 156/200. Train set: Average loss: 0.5366\n",
      "Train: [0/6252 (0%)]\tLoss: 0.791519\n",
      "Train: [400/6252 (6%)]\tLoss: 0.502692\n",
      "Train: [800/6252 (13%)]\tLoss: 0.465401\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.546656\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.366400\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.493675\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.398649\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.549103\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.565211\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.618724\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.466196\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.549640\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.488066\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.596597\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.452386\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.490042\n",
      "Epoch: 157/200. Train set: Average loss: 0.5099\n",
      "Train: [0/6252 (0%)]\tLoss: 1.029816\n",
      "Train: [400/6252 (6%)]\tLoss: 0.450193\n",
      "Train: [800/6252 (13%)]\tLoss: 0.292226\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.520546\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.486411\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.473022\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.601573\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.573625\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.441750\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.620928\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.579990\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.396174\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.509068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [5200/6252 (83%)]\tLoss: 0.340969\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.583736\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.588237\n",
      "Epoch: 158/200. Train set: Average loss: 0.5053\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.441759\n",
      "Train: [800/6252 (13%)]\tLoss: 0.565414\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.445712\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.456197\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.515689\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.496468\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.644763\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.359653\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.484916\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.583652\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.659231\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.291982\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.460770\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.552823\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.519390\n",
      "Epoch: 159/200. Train set: Average loss: 0.4962\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.440664\n",
      "Train: [800/6252 (13%)]\tLoss: 0.360225\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.691961\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.492482\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.494520\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.633732\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.470707\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.381618\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.525450\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.494086\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.520007\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.608329\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.538113\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.590894\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.630558\n",
      "Epoch: 160/200. Train set: Average loss: 0.5198\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.604747\n",
      "Train: [800/6252 (13%)]\tLoss: 0.641715\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.685775\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.317276\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.440165\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.591571\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.365165\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.645217\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.598028\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.647424\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.406489\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.373263\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.566216\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.353952\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.554641\n",
      "Epoch: 161/200. Train set: Average loss: 0.5250\n",
      "Train: [0/6252 (0%)]\tLoss: 1.080017\n",
      "Train: [400/6252 (6%)]\tLoss: 0.563503\n",
      "Train: [800/6252 (13%)]\tLoss: 0.671215\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.662154\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.575965\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.393068\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.371274\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.367357\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.508318\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.608411\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.497759\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.289457\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.666695\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.572925\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.550806\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.394580\n",
      "Epoch: 162/200. Train set: Average loss: 0.5172\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.388329\n",
      "Train: [800/6252 (13%)]\tLoss: 0.385260\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.689249\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.395463\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.649732\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.472711\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.557396\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.636007\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.505615\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.624588\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.556424\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.615024\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.505738\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.706794\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.266651\n",
      "Epoch: 163/200. Train set: Average loss: 0.5305\n",
      "Train: [0/6252 (0%)]\tLoss: 0.899948\n",
      "Train: [400/6252 (6%)]\tLoss: 0.469507\n",
      "Train: [800/6252 (13%)]\tLoss: 0.459097\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.754323\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.538168\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.412251\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.649795\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.292525\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.490936\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.692281\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.643037\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.582346\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.408438\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.406766\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.704912\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.631920\n",
      "Epoch: 164/200. Train set: Average loss: 0.5460\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.504806\n",
      "Train: [800/6252 (13%)]\tLoss: 0.582600\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.584439\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.582167\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.643623\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.573582\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.561823\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.538224\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.499986\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.501859\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.545974\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.354393\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.441396\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.205721\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.582146\n",
      "Epoch: 165/200. Train set: Average loss: 0.5113\n",
      "Train: [0/6252 (0%)]\tLoss: 1.016190\n",
      "Train: [400/6252 (6%)]\tLoss: 0.411490\n",
      "Train: [800/6252 (13%)]\tLoss: 0.511147\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.330886\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.399692\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.390204\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.683726\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.676916\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.445134\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.494280\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.674685\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.466833\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.590409\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.357204\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.495525\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.353426\n",
      "Epoch: 166/200. Train set: Average loss: 0.4933\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.551184\n",
      "Train: [800/6252 (13%)]\tLoss: 0.451659\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.598720\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.519778\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.693890\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.538056\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.647627\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.450646\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.547657\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.393128\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.383349\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.516719\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.584708\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.703794\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.547106\n",
      "Epoch: 167/200. Train set: Average loss: 0.5447\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.549740\n",
      "Train: [800/6252 (13%)]\tLoss: 0.346524\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.493686\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.394749\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.447904\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.462267\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.444910\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.590553\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.547140\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.497662\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.482755\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.471722\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.505700\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.492940\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.400070\n",
      "Epoch: 168/200. Train set: Average loss: 0.4787\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.605928\n",
      "Train: [800/6252 (13%)]\tLoss: 0.618096\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.496323\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.396630\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.397952\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.499649\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.508634\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.595532\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.600374\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.594061\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.397313\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.307081\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.378848\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.498198\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.299747\n",
      "Epoch: 169/200. Train set: Average loss: 0.4811\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.495758\n",
      "Train: [800/6252 (13%)]\tLoss: 0.452471\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.561736\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.568888\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.722605\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.345584\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.442570\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.586050\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.594980\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.557174\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.552887\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.496402\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.518361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [5600/6252 (89%)]\tLoss: 0.505435\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.431099\n",
      "Epoch: 170/200. Train set: Average loss: 0.5100\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.362804\n",
      "Train: [800/6252 (13%)]\tLoss: 0.356031\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.498809\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.402058\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.643713\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.417206\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.307090\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.387774\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.572527\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.666830\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.579430\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.504588\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.443132\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.657886\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.512450\n",
      "Epoch: 171/200. Train set: Average loss: 0.4860\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.467405\n",
      "Train: [800/6252 (13%)]\tLoss: 0.404303\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.523372\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.603239\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.553494\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.458099\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.513763\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.569300\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.490926\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.410868\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.807761\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.489702\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.593160\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.350916\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.503191\n",
      "Epoch: 172/200. Train set: Average loss: 0.5142\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.640252\n",
      "Train: [800/6252 (13%)]\tLoss: 0.291528\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.508192\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.595361\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.635179\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.535071\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.487378\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.397987\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.689053\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.492956\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.320936\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.579377\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.621583\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.559439\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.396611\n",
      "Epoch: 173/200. Train set: Average loss: 0.5187\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.520160\n",
      "Train: [800/6252 (13%)]\tLoss: 0.534241\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.503516\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.582189\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.614333\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.376914\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.589738\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.633585\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.530896\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.445484\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.419957\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.346940\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.498580\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.415296\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.354147\n",
      "Epoch: 174/200. Train set: Average loss: 0.5031\n",
      "Train: [0/6252 (0%)]\tLoss: 0.885986\n",
      "Train: [400/6252 (6%)]\tLoss: 0.509289\n",
      "Train: [800/6252 (13%)]\tLoss: 0.622516\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.412853\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.587995\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.648983\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.600729\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.405687\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.408490\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.571308\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.438379\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.743451\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.532530\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.340079\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.518211\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.339140\n",
      "Epoch: 175/200. Train set: Average loss: 0.5192\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.491309\n",
      "Train: [800/6252 (13%)]\tLoss: 0.599850\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.412202\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.287543\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.451253\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.437674\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.738190\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.482524\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.494623\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.372331\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.504108\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.578357\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.519941\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.404421\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.523516\n",
      "Epoch: 176/200. Train set: Average loss: 0.4882\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.339307\n",
      "Train: [800/6252 (13%)]\tLoss: 0.542368\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.549176\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.297016\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.625054\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.327519\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.760572\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.541846\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.457460\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.587849\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.558894\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.543896\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.415782\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.560123\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.593941\n",
      "Epoch: 177/200. Train set: Average loss: 0.5183\n",
      "Train: [0/6252 (0%)]\tLoss: 0.647308\n",
      "Train: [400/6252 (6%)]\tLoss: 0.535139\n",
      "Train: [800/6252 (13%)]\tLoss: 0.412431\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.448627\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.516848\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.555898\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.402137\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.553392\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.456339\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.481128\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.255917\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.457743\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.354034\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.391441\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.493793\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.455349\n",
      "Epoch: 178/200. Train set: Average loss: 0.4569\n",
      "Train: [0/6252 (0%)]\tLoss: 0.949890\n",
      "Train: [400/6252 (6%)]\tLoss: 0.467645\n",
      "Train: [800/6252 (13%)]\tLoss: 0.513414\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.545515\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.647810\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.447343\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.503729\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.552289\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.144881\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.375240\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.611935\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.474348\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.512885\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.451688\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.515650\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.405494\n",
      "Epoch: 179/200. Train set: Average loss: 0.4827\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.553511\n",
      "Train: [800/6252 (13%)]\tLoss: 0.416058\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.663996\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.473766\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.576245\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.399080\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.521597\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.492030\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.453466\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.548266\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.568102\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.338351\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.666326\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.347419\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.543626\n",
      "Epoch: 180/200. Train set: Average loss: 0.4971\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.633276\n",
      "Train: [800/6252 (13%)]\tLoss: 0.461974\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.600230\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.697868\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.373339\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.667017\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.441422\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.585959\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.484762\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.573619\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.545512\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.556422\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.748340\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.514102\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.500106\n",
      "Epoch: 181/200. Train set: Average loss: 0.5564\n",
      "Train: [0/6252 (0%)]\tLoss: 0.959396\n",
      "Train: [400/6252 (6%)]\tLoss: 0.660409\n",
      "Train: [800/6252 (13%)]\tLoss: 0.396998\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.362770\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.607570\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.511113\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.475763\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.459144\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.352161\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.508945\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.697676\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.554204\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.642335\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.466275\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.698871\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.565976\n",
      "Epoch: 182/200. Train set: Average loss: 0.5363\n",
      "Train: [0/6252 (0%)]\tLoss: 0.966232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [400/6252 (6%)]\tLoss: 0.349109\n",
      "Train: [800/6252 (13%)]\tLoss: 0.392637\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.505444\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.482934\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.445423\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.494545\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.504889\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.498225\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.597750\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.689770\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.598589\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.553925\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.410619\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.459592\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.361089\n",
      "Epoch: 183/200. Train set: Average loss: 0.4875\n",
      "Train: [0/6252 (0%)]\tLoss: 0.955780\n",
      "Train: [400/6252 (6%)]\tLoss: 0.533532\n",
      "Train: [800/6252 (13%)]\tLoss: 0.474870\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.629615\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.659989\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.814552\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.439764\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.391351\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.452270\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.548329\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.350555\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.611963\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.454989\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.490416\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.637621\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.495954\n",
      "Epoch: 184/200. Train set: Average loss: 0.5288\n",
      "Train: [0/6252 (0%)]\tLoss: 0.976410\n",
      "Train: [400/6252 (6%)]\tLoss: 0.475414\n",
      "Train: [800/6252 (13%)]\tLoss: 0.556248\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.380551\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.344861\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.350761\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.447562\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.453878\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.242315\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.459565\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.259324\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.606100\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.418652\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.577751\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.640935\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.485721\n",
      "Epoch: 185/200. Train set: Average loss: 0.4536\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.396983\n",
      "Train: [800/6252 (13%)]\tLoss: 0.460881\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.477259\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.644622\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.513593\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.362414\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.708659\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.546050\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.448336\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.380917\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.559200\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.515825\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.492081\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.462121\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.652194\n",
      "Epoch: 186/200. Train set: Average loss: 0.5049\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.441179\n",
      "Train: [800/6252 (13%)]\tLoss: 0.405194\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.398699\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.641314\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.419658\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.545916\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.573452\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.295908\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.503706\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.313123\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.522356\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.422043\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.461408\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.462137\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.486731\n",
      "Epoch: 187/200. Train set: Average loss: 0.4568\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.513081\n",
      "Train: [800/6252 (13%)]\tLoss: 0.488812\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.565964\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.506546\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.328970\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.393129\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.623176\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.556300\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.403588\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.435915\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.602351\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.680321\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.557018\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.347446\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.306657\n",
      "Epoch: 188/200. Train set: Average loss: 0.4856\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.443670\n",
      "Train: [800/6252 (13%)]\tLoss: 0.470866\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.391690\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.570224\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.573044\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.739119\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.447791\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.499116\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.483669\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.377354\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.472672\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.590751\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.612646\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.441592\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.363740\n",
      "Epoch: 189/200. Train set: Average loss: 0.5004\n",
      "Train: [0/6252 (0%)]\tLoss: 0.948807\n",
      "Train: [400/6252 (6%)]\tLoss: 0.310744\n",
      "Train: [800/6252 (13%)]\tLoss: 0.588668\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.642430\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.401339\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.387649\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.487863\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.302185\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.443796\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.651418\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.414387\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.523964\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.752956\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.405566\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.501352\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.563348\n",
      "Epoch: 190/200. Train set: Average loss: 0.4935\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.380958\n",
      "Train: [800/6252 (13%)]\tLoss: 0.605540\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.510541\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.595303\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.537740\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.398830\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.686158\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.494353\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.444757\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.312771\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.301025\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.682674\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.457220\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.532070\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.744008\n",
      "Epoch: 191/200. Train set: Average loss: 0.5178\n",
      "Train: [0/6252 (0%)]\tLoss: 1.098145\n",
      "Train: [400/6252 (6%)]\tLoss: 0.345042\n",
      "Train: [800/6252 (13%)]\tLoss: 0.499371\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.245763\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.506475\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.526223\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.546977\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.610679\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.609490\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.404636\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.286965\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.606781\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.329000\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.662075\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.652375\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.648250\n",
      "Epoch: 192/200. Train set: Average loss: 0.4986\n",
      "Train: [0/6252 (0%)]\tLoss: 0.969879\n",
      "Train: [400/6252 (6%)]\tLoss: 0.498173\n",
      "Train: [800/6252 (13%)]\tLoss: 0.553230\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.373647\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.347218\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.508073\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.599254\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.552157\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.457312\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.706324\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.354219\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.466462\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.597546\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.617946\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.709208\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.616246\n",
      "Epoch: 193/200. Train set: Average loss: 0.5303\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.441661\n",
      "Train: [800/6252 (13%)]\tLoss: 0.397734\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.391882\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.655537\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.495789\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.633809\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.445455\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.534536\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.341860\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.643891\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.539256\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.614436\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.316324\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.631432\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.518964\n",
      "Epoch: 194/200. Train set: Average loss: 0.5080\n",
      "Train: [0/6252 (0%)]\tLoss: 0.975250\n",
      "Train: [400/6252 (6%)]\tLoss: 0.498750\n",
      "Train: [800/6252 (13%)]\tLoss: 0.446568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [1200/6252 (19%)]\tLoss: 0.625658\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.525472\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.458352\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.476045\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.400514\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.346127\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.441209\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.451306\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.454720\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.498756\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.489453\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.569750\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.340480\n",
      "Epoch: 195/200. Train set: Average loss: 0.4725\n",
      "Train: [0/6252 (0%)]\tLoss: 0.906952\n",
      "Train: [400/6252 (6%)]\tLoss: 0.488501\n",
      "Train: [800/6252 (13%)]\tLoss: 0.475416\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.583453\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.257334\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.593115\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.560255\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.366765\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.652238\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.492198\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.507306\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.527707\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.699226\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.276770\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.393194\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.592983\n",
      "Epoch: 196/200. Train set: Average loss: 0.4930\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.547913\n",
      "Train: [800/6252 (13%)]\tLoss: 0.351423\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.647055\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.614986\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.596929\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.290995\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.637434\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.577135\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.437640\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.444306\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.435511\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.549219\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.448697\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.508805\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.495674\n",
      "Epoch: 197/200. Train set: Average loss: 0.5075\n",
      "Train: [0/6252 (0%)]\tLoss: 0.000000\n",
      "Train: [400/6252 (6%)]\tLoss: 0.704546\n",
      "Train: [800/6252 (13%)]\tLoss: 0.413090\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.538659\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.345272\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.555422\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.439171\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.545088\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.398623\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.355401\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.500167\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.585806\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.305579\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.614035\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.477728\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.684582\n",
      "Epoch: 198/200. Train set: Average loss: 0.4918\n",
      "Train: [0/6252 (0%)]\tLoss: 0.994171\n",
      "Train: [400/6252 (6%)]\tLoss: 0.450369\n",
      "Train: [800/6252 (13%)]\tLoss: 0.327815\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.596725\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.607314\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.392032\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.453625\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.574173\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.497297\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.494507\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.544107\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.500527\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.580012\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.551048\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.390824\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.583710\n",
      "Epoch: 199/200. Train set: Average loss: 0.5042\n",
      "Train: [0/6252 (0%)]\tLoss: 0.916779\n",
      "Train: [400/6252 (6%)]\tLoss: 0.486908\n",
      "Train: [800/6252 (13%)]\tLoss: 0.463637\n",
      "Train: [1200/6252 (19%)]\tLoss: 0.565767\n",
      "Train: [1600/6252 (26%)]\tLoss: 0.607241\n",
      "Train: [2000/6252 (32%)]\tLoss: 0.599043\n",
      "Train: [2400/6252 (38%)]\tLoss: 0.591697\n",
      "Train: [2800/6252 (45%)]\tLoss: 0.671523\n",
      "Train: [3200/6252 (51%)]\tLoss: 0.645076\n",
      "Train: [3600/6252 (58%)]\tLoss: 0.606085\n",
      "Train: [4000/6252 (64%)]\tLoss: 0.244444\n",
      "Train: [4400/6252 (70%)]\tLoss: 0.439256\n",
      "Train: [4800/6252 (77%)]\tLoss: 0.637016\n",
      "Train: [5200/6252 (83%)]\tLoss: 0.446737\n",
      "Train: [5600/6252 (89%)]\tLoss: 0.480818\n",
      "Train: [6000/6252 (96%)]\tLoss: 0.451069\n",
      "Epoch: 200/200. Train set: Average loss: 0.5292\n",
      "CPU times: user 3min 58s, sys: 13.9 s, total: 4min 12s\n",
      "Wall time: 4min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fit(train_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(dataset, labels, model):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        embeddings = []\n",
    "\n",
    "        for data in dataset:\n",
    "\n",
    "            embeddings.append( \n",
    "                np.array( \n",
    "                    model.get_embedding(data).detach().numpy() ) )\n",
    "\n",
    "    return np.array(embeddings), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6252, 20)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs,labels = extract_embeddings(data_set_shuffled , labels, model)\n",
    "embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.manifold import TSNE\n",
    "# embedded_2 = TSNE(n_components=2, learning_rate='auto',\n",
    "#      init='random').fit_transform(embs)\n",
    "tsne = TSNE(n_components=2, perplexity = 5, learning_rate='auto',init='random',  n_jobs=-1)\n",
    "mds = sklearn.manifold.MDS(n_components=2,metric=True, \n",
    "                                  n_init=4, \n",
    "                                  max_iter=100,\n",
    "                                  verbose=0, eps=0.001, n_jobs=-1, random_state= 1024, dissimilarity='euclidean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embeddings(embeddings, targets, xlim=None, ylim=None):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    targets = np.array(targets)\n",
    "    colors = ['r', 'b']\n",
    "    shapes = ['*', '^']\n",
    "    for cls in set(targets):\n",
    "        mask = targets == cls\n",
    "        cls_emb = embeddings[mask]\n",
    "        plt.scatter(cls_emb[:,0], cls_emb[:,1], alpha=0.5, marker = shapes[cls],c = colors[cls])\n",
    "\n",
    "    plt.legend(set(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smaples_for_plotting(percentage, labels, data):\n",
    "\n",
    "    # print(data)\n",
    "    percentage = 0.5\n",
    "    labels = np.array(labels)\n",
    "    label_to_indices = {label: np.where(labels == label)[0]\n",
    "                             for label in labels}\n",
    "\n",
    "\n",
    "    true_num = int( len(label_to_indices[1]) * percentage )\n",
    "    false_num = int( len(label_to_indices[0]) * percentage )\n",
    "\n",
    "    positive_index = np.random.choice( label_to_indices[1], true_num)\n",
    "    negative_index= np.random.choice(label_to_indices[0], false_num)\n",
    "\n",
    "    index = np.concatenate( [positive_index, negative_index], axis = 0)\n",
    "\n",
    "    return data[index], labels[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_resample, labels_resample = smaples_for_plotting(0.5, labels, embs)\n",
    "orig_data, labels_resample_orig = smaples_for_plotting(0.5, labels, data_set_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3126, 20)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs_resample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedded_2_mds = mds.fit_transform(embs_resample.astype(np.float64)) # float64 fix array not symmetric issue\n",
    "plot_embeddings(embedded_2_mds, labels_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedded_2_origin_mds = mds.fit_transform(orig_data)\n",
    "plot_embeddings(embedded_2_origin_mds, labels_resample_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
